{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use(\"PDF\")\n",
    "import glob,time,scipy,pickle\n",
    "from astropy.io import fits as pf\n",
    "import scipy.interpolate\n",
    "from scipy.special import erf\n",
    "from scipy import stats\n",
    "from pylab import *\n",
    "from subprocess import call\n",
    "from scipy.optimize import fmin_powell\n",
    "from scipy.ndimage import gaussian_filter, convolve\n",
    "topdir='/Users/cslage/Research/LSST/code/GUI/brighter_fatter/'\n",
    "thedir=topdir+'notebooks/'\n",
    "#sys.path.append(thedir)\n",
    "#import forward_sky\n",
    "datadir=topdir+'/20171128_002_spots_VBB60/'\n",
    "kerneldir = datadir\n",
    "\n",
    "configfile=topdir+'sextractor/default-array_dither.sex'\n",
    "paramfile=topdir+'sextractor/default-array_dither.param'\n",
    "maskdir=topdir+'sextractor/masks/'\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files have been crosstalk subtracted\n",
    "filelist=np.sort(glob.glob(datadir+'ITL-3800C-002_spot_spot_???_20171128??????_ct.fits'))\n",
    "zfilelist = []\n",
    "# Now select the files in best focus from earlier analysis\n",
    "for file in filelist:\n",
    "    seqno = int(file.split('_')[-3])\n",
    "    if seqno in [228 + 20 * n for n in range(20)]:\n",
    "        zfilelist.append(file)\n",
    "print(len(zfilelist))\n",
    "#print(zfilelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overscan_xy(image,x_overscan_start,x_overscan_end,y_overscan_start,y_overscan_end):\n",
    "    overscan=image[:y_overscan_start,x_overscan_start+1:x_overscan_end]\n",
    "    image=image[:y_overscan_start,:x_overscan_start]\n",
    "    finalimg=image-matrix(median(overscan,axis=1)).T*np.ones(shape(image)[1])\n",
    "    return array(finalimg)\n",
    "\n",
    "def make_reg_from_ldac(cat_ldac_file,text_tag):\n",
    "    thecat=pf.getdata(cat_ldac_file,'LDAC_OBJECTS')\n",
    "    f = open(cat_ldac_file+'.reg','w')\n",
    "    for i in range(len(thecat)):\n",
    "        xcoo,ycoo=thecat['XWIN_IMAGE'][i],thecat['YWIN_IMAGE'][i]\n",
    "        r=thecat['A_IMAGE'][i]\n",
    "        thetext=thecat[text_tag][i]\n",
    "        f.write('circle '+str(xcoo)+' '+str(ycoo)+' '+str(r)+'#text=\"'+str(thetext)+'\"\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs sextractor on the files to find the spots.  This only needs to be done once\n",
    "for fitsfilename in zfilelist: \n",
    "    tfile1=time.time() \n",
    "    for i in range(16):\n",
    "        tstart=time.time() \n",
    "        extname=pf.getheader(fitsfilename,i+1)['EXTNAME'] \n",
    "        img=pf.getdata(fitsfilename,extname) \n",
    "        overscansubimg=remove_overscan_xy(img,509,542,2000,2022) \n",
    "        # cut off the overscan \n",
    "        outname=fitsfilename[:-5]+extname+'.fits' \n",
    "        pf.writeto(outname,overscansubimg,clobber=True) \n",
    "        test=call([\"sex\",outname,\"-c\",configfile,\"-CATALOG_NAME\",outname+'.cat']) \n",
    "        make_reg_from_ldac(outname+'.cat','NUMBER') \n",
    "        tend=time.time() \n",
    "        print extname+\" time: \"+str(tend-tstart)[:4] \n",
    "        print \"Time taken for file \"+str(fitsfilename[-26:-23])+\": \"+str(time.time()-tfile1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First get some spot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overscan_xy(image,x_overscan_start,x_overscan_end,y_overscan_start,y_overscan_end):\n",
    "    overscan=image[:y_overscan_start,x_overscan_start+1:x_overscan_end]\n",
    "    image=image[:y_overscan_start,:x_overscan_start]\n",
    "    finalimg=image-matrix(median(overscan,axis=1)).T*np.ones(shape(image)[1])\n",
    "    return array(finalimg)\n",
    "\n",
    "class Array2dSet:\n",
    "    def __init__(self,xmin,xmax,nx,ymin,ymax,ny,nstamps):\n",
    "        # This packages up a set of nstamps postage stamp images,\n",
    "        # each image of which is nx * ny pixels\n",
    "        self.nx=nx\n",
    "        self.ny=ny\n",
    "        self.nstamps=nstamps\n",
    "\n",
    "        self.xmin=xmin\n",
    "        self.ymin=ymin\n",
    "        \n",
    "        self.xmax=xmax\n",
    "        self.ymax=ymax\n",
    "        \n",
    "        self.dx=(xmax-xmin)/nx\n",
    "        self.dy=(ymax-ymin)/ny\n",
    "        \n",
    "        self.x=linspace(xmin+self.dx/2,xmax-self.dx/2,nx)\n",
    "        self.y=linspace(ymin+self.dy/2,ymax-self.dy/2,ny)\n",
    "\n",
    "        self.data=zeros([nx,ny,nstamps])\n",
    "        self.xoffset=zeros([nstamps])\n",
    "        self.yoffset=zeros([nstamps])\n",
    "        self.imax=zeros([nstamps])\n",
    "\n",
    "\n",
    "def BuildSpotList(fitsfilename, segmentnumber, numspots, nx, ny, minsize, maxsize):\n",
    "    stampxmin = -(int(nx/2)+0.5)\n",
    "    stampxmax = -stampxmin\n",
    "    stampymin = -(int(ny/2)+0.5)\n",
    "    stampymax = -stampymin\n",
    "    xcoomin = 50\n",
    "    xcoomax = 450\n",
    "    ycoomin = 1400\n",
    "    ycoomax = 1900\n",
    "    spotlist = Array2dSet(stampxmin,stampxmax,nx,stampymin,stampymax,ny,numspots)\n",
    "    hdr=pf.getheader(fitsfilename,segmentnumber)\n",
    "    extname = hdr['EXTNAME']\n",
    "    img=pf.getdata(fitsfilename,extname) \n",
    "    overscansubimg=remove_overscan_xy(img,509,542,2000,2022) \n",
    "    catname=fitsfilename[:-5]+extname+'.fits.cat.reg' \n",
    "    catfile = open(catname,'r')\n",
    "    catlines = catfile.readlines()\n",
    "    #print(catlines)\n",
    "    catfile.close()\n",
    "    n=0\n",
    "    for line in catlines:\n",
    "        try:\n",
    "            size = float(line.split()[3].split('#')[0])\n",
    "            if size < minsize or size > maxsize:\n",
    "                continue\n",
    "            xcoord = float(line.split()[1])\n",
    "            ycoord = float(line.split()[2])\n",
    "            if xcoord < xcoomin or xcoord > xcoomax or ycoord < ycoomin or ycoord > ycoomax:\n",
    "                continue\n",
    "            xint = int(xcoord-0.5)\n",
    "            yint = int(ycoord-0.5)\n",
    "            xmin = xint - int(nx/2)\n",
    "            xmax = xint + int(nx/2) + 1\n",
    "            ymin = yint - int(ny/2)\n",
    "            ymax = yint + int(ny/2) + 1\n",
    "            stamp = overscansubimg[ymin:ymax, xmin:xmax]\n",
    "           \n",
    "            xsum = 0.0\n",
    "            ysum = 0.0\n",
    "            datasum = 0.0\n",
    "             \n",
    "            for i in range(nx):\n",
    "                for j in range(ny):\n",
    "                    spotlist.data[i,j,n] = float(stamp[j,i])                    \n",
    "                    ysum += spotlist.y[j] * spotlist.data[i,j,n]\n",
    "                    xsum += spotlist.x[i] * spotlist.data[i,j,n]\n",
    "                    datasum += spotlist.data[i,j,n]\n",
    "            xoff = xsum / datasum\n",
    "            yoff = ysum / datasum\n",
    "            spotlist.xoffset[n] = xoff\n",
    "            spotlist.yoffset[n] = yoff\n",
    "            #spotlist.xoffset[n] = xcoord - xint - 1.0\n",
    "            #spotlist.yoffset[n] = ycoord - yint - 1.0     \n",
    "            #print \"Spot = %d, calc_off = (%f,%f), sex_off = (%f,%f)\"%(n,xoff,yoff,xcoord-xint-1.0,ycoord-yint-1.0)\n",
    "            n += 1\n",
    "            if n == numspots:\n",
    "                return spotlist\n",
    "        except:\n",
    "            continue\n",
    "    # Reaching this point means we found less spots than requested.\n",
    "    newspotlist = Array2dSet(stampxmin,stampxmax,nx,stampymin,stampymax,ny,n)\n",
    "    newspotlist.xoffset = spotlist.xoffset[0:n]\n",
    "    newspotlist.yoffset = spotlist.yoffset[0:n]\n",
    "    newspotlist.data = spotlist.data[:,:,0:n]\n",
    "    del spotlist\n",
    "    return newspotlist\n",
    "\n",
    "\n",
    "def Area(xl, xh, yl, yh, sigmax, sigmay, Imax):\n",
    "    # Calculates how much of a 2D Gaussian falls within a rectangular box\n",
    "    ssigx = sqrt(2) * sigmax\n",
    "    ssigy = sqrt(2) * sigmay    \n",
    "    I = (erf(xh/ssigx)-erf(xl/ssigx))*(erf(yh/ssigy)-erf(yl/ssigy))\n",
    "    return Imax * I / 4.0\n",
    "\n",
    "\n",
    "def FOM(params):\n",
    "    [sigmax, sigmay, sky] = params\n",
    "    result = forward_sky.forward_sky(spotlist,sigmax,sigmay,sky)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segmentnumber in range(1,17):\n",
    "    hdr=pf.getheader(zfilelist[0],segmentnumber)\n",
    "    extname = hdr['EXTNAME']\n",
    "    print segmentnumber, extname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the spotlist building and look at a typical spot\n",
    "nx = 11\n",
    "ny = 11\n",
    "numspots =400\n",
    "spotnum = 2\n",
    "segmentnumber = 13\n",
    "\n",
    "fitsfilename = zfilelist[1]\n",
    "print(fitsfilename)\n",
    "    \n",
    "spotlist = BuildSpotList(fitsfilename, segmentnumber, numspots, nx, ny, 0.7, 1.4)\n",
    "print(\"nstamps = %d\"%spotlist.nstamps)\n",
    "#args = ()\n",
    "#param0 = [1.0, 1.0, 1.0]\n",
    "#Result = fmin_powell(FOM, param0, args)\n",
    "#OldResult = Result\n",
    "#print \"Result = \", Result\n",
    "\n",
    "spot = 4.4 * spotlist.data[:,:,spotnum] # Convert to electrons\n",
    "print(\"xoff = %f, yoff = %f\"%(spotlist.xoffset[spotnum],spotlist.yoffset[spotnum]))\n",
    "\n",
    "imshow(spot, interpolation='nearest')\n",
    "colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now extract the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    peak = spotlist.data[:,:,i].max()\n",
    "    tot = spotlist.data[:,:,i].sum()\n",
    "    ratio = tot/peak\n",
    "    print(peak, tot, ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Array2d:\n",
    "    def __init__(self,xmin,xmax,nx,ymin,ymax,ny):\n",
    "        # Each image is nx * ny pixels\n",
    "        self.nx=nx\n",
    "        self.ny=ny\n",
    "\n",
    "        self.xmin=xmin\n",
    "        self.ymin=ymin\n",
    "        \n",
    "        self.xmax=xmax\n",
    "        self.ymax=ymax\n",
    "        \n",
    "        self.dx=(xmax-xmin)/nx\n",
    "        self.dy=(ymax-ymin)/ny\n",
    "        \n",
    "        self.x=linspace(xmin+self.dx/2,xmax-self.dx/2,nx)\n",
    "        self.y=linspace(ymin+self.dy/2,ymax-self.dy/2,ny)\n",
    "\n",
    "        self.cov=zeros([nx,ny])\n",
    "        self.kernel=zeros([nx,ny])       \n",
    "        \n",
    "    def PrintKernel(self, filename):\n",
    "        file = open(filename, 'w')\n",
    "        line = 'X\\tY\\tCovariance\\t\\t\\tKernel\\n'\n",
    "        file.write(line)\n",
    "        for i in range(self.nx):\n",
    "            for j in range(self.ny):\n",
    "                line = '%d\\t%d\\t%0.12e\\t%0.12e\\n'%(i,j,self.cov[i,j],self.kernel[i,j])\n",
    "                file.write(line)\n",
    "        file.close()\n",
    "        return\n",
    "\n",
    "def ReadConfigFile(filename):\n",
    "    # This reads the Poisson simulator config file for\n",
    "    # the settings that were run\n",
    "    # and returns a dictionary with the values\n",
    "\n",
    "    with open(filename,'r') as file:\n",
    "        lines=file.readlines()\n",
    "    lines = [ l.strip() for l in lines ]\n",
    "    lines = [ l.split() for l in lines if len(l) > 0 and l[0] != '#' ]\n",
    "    for line in lines:\n",
    "        if line[1] != '=':\n",
    "            print \"Check line: \",line\n",
    "            raise IOError(\"Error reading config file %s\"%filename)\n",
    "    config = {}\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # First get the ordered pairs\n",
    "            config.update({line[0]:[eval(line[2]), eval(line[3])]})\n",
    "        except:\n",
    "            try:\n",
    "                # Then get the numeric values\n",
    "                config.update({line[0]:eval(line[2])})\n",
    "            except:\n",
    "                try:\n",
    "                    # Last, get the strings\n",
    "                    config.update({line[0]:str(line[2])})\n",
    "                except:\n",
    "                    pass\n",
    "    return config\n",
    "\n",
    "\n",
    "def ReadAreaFile(filename, arr, Area_0, NxCenter, NyCenter):\n",
    "    # This reads the simulated pixel area file\n",
    "    # and returns an array with the covariances\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    lines.remove(lines[0]) # Strip the title line    \n",
    "    for line in lines:\n",
    "        items = line.split()\n",
    "        i = int(items[0])\n",
    "        j = int(items[1])\n",
    "        area = float(items[2])\n",
    "        ii = i + (arr.nx - 1)/2 - NxCenter \n",
    "        jj = j + (arr.ny - 1)/2 - NyCenter \n",
    "        arr.cov[ii,jj] += (area - Area_0) / Area_0\n",
    "    return arr\n",
    "\n",
    "def ReadMeasurementFile(filename, arr):\n",
    "    # This reads the measured correlation data file\n",
    "    # and returns an array with the covariances\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    lines.remove(lines[0]) # Strip the title line\n",
    "    for i in range(3):\n",
    "        lines.remove(lines[-1]) # Strip the last three lines\n",
    "\n",
    "    for line in lines:\n",
    "        items = line.split()\n",
    "        i = int(items[0])\n",
    "        j = int(items[1])\n",
    "        cov = float(items[2])\n",
    "        if (i > 0 or j > 0) and cov < 0.0:\n",
    "            cov = 0.0\n",
    "        for xsign in [-1,1]:\n",
    "            ii = i * xsign + (arr.nx - 1)/2\n",
    "            for ysign in [-1,1]:\n",
    "                jj = j * ysign + (arr.ny - 1)/2\n",
    "                arr.cov[ii,jj] = cov # Baseline\n",
    "    return arr\n",
    "\n",
    "\n",
    "def SOR(arr, w):\n",
    "    hsquared =  arr.dx * arr.dy;\n",
    "    omw = 1.0 - w;\n",
    "    w4 = w / 4.0\n",
    "    for i in range(1, arr.nx-1):\n",
    "        for j in range(1, arr.ny-1):\n",
    "            arr.kernel[i,j] = omw * arr.kernel[i,j] + w4 * (arr.kernel[i-1,j] + arr.kernel[i+1,j] + arr.kernel[i,j-1] + arr.kernel[i,j+1] + hsquared * arr.cov[i,j])\n",
    "    return arr\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, read the .cfg file\n",
    "configfile = kerneldir+'pixel.cfg'\n",
    "run = 0\n",
    "ConfigData = ReadConfigFile(configfile)\n",
    "outputfilebase = ConfigData[\"outputfilebase\"]\n",
    "outputfiledir = ConfigData[\"outputfiledir\"]\n",
    "Nx = ConfigData[\"PixelBoundaryNx\"]\n",
    "Ny = ConfigData[\"PixelBoundaryNy\"]\n",
    "XCenter = ConfigData[\"FilledPixelCoords_0_0\"][0]\n",
    "YCenter = ConfigData[\"FilledPixelCoords_0_0\"][1]\n",
    "PixelSizeX = ConfigData[\"PixelSizeX\"]\n",
    "PixelSizeY = ConfigData[\"PixelSizeY\"]\n",
    "NxCenter = int((XCenter - ConfigData[\"PixelBoundaryLowerLeft\"][0]) / PixelSizeX)\n",
    "NyCenter = int((YCenter - ConfigData[\"PixelBoundaryLowerLeft\"][1]) / PixelSizeY)\n",
    "NumElec = ConfigData[\"CollectedCharge_0_0\"]\n",
    "NewNx = NewNy = 21\n",
    "NewNxCenter = (NewNx - 1) / 2\n",
    "NewNyCenter = (NewNy - 1) / 2\n",
    "\n",
    "filename = kerneldir + 'corr_meas_model_central_csteps_7_07jun18.txt'\n",
    "kernel = Array2d(0,NewNx,NewNx,0,NewNy,NewNy)\n",
    "kernel = ReadMeasurementFile(filename, kernel)\n",
    "kernel.cov /= NumElec\n",
    "\n",
    "w = 1.9\n",
    "for n in range(2000):\n",
    "    kernel = SOR(kernel,w)\n",
    "\n",
    "figure()\n",
    "suptitle('B-F Kernel extracted from 3800 Flats')\n",
    "subplots_adjust(wspace=0.8,hspace=0.5)\n",
    "subplot(2,3,1)\n",
    "title(\"Covariances(*1E7)\",fontsize=9)\n",
    "imshow(kernel.cov*1E7, interpolation='nearest')\n",
    "colorbar(fraction=0.046)\n",
    "subplot(2,3,2)\n",
    "title(\"Covariances(*1E7) - X-Slice\",fontsize=9)\n",
    "plot(kernel.x,kernel.cov[:,NewNyCenter]*1E7)\n",
    "subplot(2,3,3)\n",
    "title(\"Covariances(*1E7) - Y-Slice\",fontsize=9)\n",
    "plot(kernel.y,kernel.cov[NewNxCenter,:]*1E7)\n",
    "subplot(2,3,4)\n",
    "title(\"Kernel(*1E7)\",fontsize=9)\n",
    "imshow(kernel.kernel*1E7, interpolation='nearest')\n",
    "colorbar(fraction=0.046)\n",
    "subplot(2,3,5)\n",
    "title(\"Kernel(*1E7) - X-Slice\",fontsize=9)\n",
    "plot(kernel.x,kernel.kernel[:,NewNyCenter]*1E7)\n",
    "subplot(2,3,6)\n",
    "title(\"Kernel(*1E7) - Y-Slice\",fontsize=9)\n",
    "plot(kernel.y,kernel.kernel[NewNxCenter,:]*1E7)\n",
    "\n",
    "savefig(kerneldir+\"Kernel_Plot_Model_Central_CSteps_7_07Jun18.pdf\")\n",
    "kernel.PrintKernel(datadir+'kernel_model_central_csteps_7_07jun18.txt')\n",
    "\n",
    "pickle_out = open(datadir+\"kernel_model_central_csteps_7_07jun18.pickle\",\"wb\")\n",
    "pickle.dump(kernel, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the convolution of the kernel with the spot look like?\n",
    "spot_kernel=convolve(spot,kernel.kernel,mode='constant',cval=0.0)\n",
    "imshow(spot_kernel, interpolation='nearest')\n",
    "colorbar()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implement the correction\n",
    "# Trying 4th order corrections\n",
    "def Dx(image):\n",
    "    dx = zeros(image.shape)\n",
    "    for i in range(2,image.shape[0]-2):\n",
    "        for j in range(image.shape[1]):\n",
    "            dx[i,j] = (-image[i+2,j] + 8.0 * image[i+1,j] - 8.0 * image[i-1,j] + image[i-2,j])/12.0\n",
    "    return dx\n",
    "\n",
    "def Dy(image):\n",
    "    dy = zeros(image.shape)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(2,image.shape[1]-2):\n",
    "            dy[i,j] = (-image[i,j+2] + 8.0 * image[i,j+1] - 8.0 * image[i,j-1] + image[i,j-2])/12.0\n",
    "    return dy\n",
    "\n",
    "def D2(image):\n",
    "    d2 = zeros(image.shape)\n",
    "    for i in range(1,image.shape[0]-1):\n",
    "        for j in range(1,image.shape[1]-1):\n",
    "            d2[i,j] = (4.0 * (image[i+1,j] + image[i-1,j] + image[i,j+1] + image[i,j-1]) + \\\n",
    "                       (image[i+1,j+1] + image[i+1,j-1] + image[i-1,j+1] + image[i-1,j-1]) - \\\n",
    "                       20.0 * image[i,j]) / 6.0\n",
    "    return d2\n",
    "\n",
    "def Correction(data, kernel):\n",
    "    int_term = convolve(data,kernel,mode='constant',cval=0.0)\n",
    "    term1 = Dx(data) * Dx(int_term) + Dy(data)* Dy(int_term)\n",
    "    term2 = data * D2(int_term)\n",
    "    correction = (term1 + term2) / 2.0\n",
    "    #print data.sum(), kernel.sum(), int_term.sum(), correction.sum()\n",
    "    return correction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implement the correction - This is second order\n",
    "# This hasn't worked as well, so is included just for completeness\n",
    "\"\"\"\n",
    "def Dx(image):\n",
    "    dx = zeros(image.shape)\n",
    "    for i in range(1,image.shape[0]-1):\n",
    "        for j in range(image.shape[1]):\n",
    "            dx[i,j] = (image[i+1,j] - image[i-1,j])/2.0\n",
    "    return dx\n",
    "\n",
    "def Dy(image):\n",
    "    dy = zeros(image.shape)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(1,image.shape[1]-1):\n",
    "            dy[i,j] = (image[i,j+1] - image[i,j-1])/2.0\n",
    "    return dy\n",
    "\n",
    "def D2(image):\n",
    "    d2 = zeros(image.shape)\n",
    "    for i in range(1,image.shape[0]-1):\n",
    "        for j in range(1,image.shape[1]-1):\n",
    "            d2[i,j] = (image[i+1,j] + image[i-1,j] + image[i,j+1] + image[i,j-1] - 4.0 * image[i,j])\n",
    "    return d2\n",
    "\n",
    "def Correction(data, kernel):\n",
    "    int_term = convolve(data,kernel,mode='constant',cval=0.0)\n",
    "    term1 = Dx(data) * Dx(int_term) + Dy(data)* Dy(int_term)\n",
    "    term2 = data * D2(int_term)\n",
    "    correction = (term1 + term2) / 2.0\n",
    "    return correction\n",
    "\n",
    "correction = Correction(spot, kernel.kernel)\n",
    "imshow(correction, interpolation ='nearest')\n",
    "colorbar()\n",
    "show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try it on a single spot\n",
    "newspot = copy(spot)\n",
    "correction = zeros(spot.shape)\n",
    "diff = 100.0\n",
    "# Iterate to convergence\n",
    "while diff > 1.0E-6:\n",
    "    lastcorrection = copy(correction)\n",
    "    correction = Correction(newspot, kernel.kernel)\n",
    "    newspot = spot + correction\n",
    "    diff = ((lastcorrection - correction) * (lastcorrection - correction)).sum()\n",
    "    print \"Diff = %f\"%diff\n",
    "\n",
    "print correction.max(), correction.min()\n",
    "figure(figsize=(16,8))\n",
    "subplots_adjust(wspace=0.5)\n",
    "subplot(2,3,1)\n",
    "title(\"X\")\n",
    "plot(spotlist.x, spot[:,5], label='Spot')\n",
    "plot(spotlist.x, newspot[:,5], label='NewSpot')\n",
    "plot(spotlist.x, 20*correction[:,5], label='20X Correction')\n",
    "subplot(2,3,2)\n",
    "title(\"Y\")\n",
    "plot(spotlist.y, spot[5,:], label='Spot')\n",
    "plot(spotlist.y, newspot[5,:], label='NewSpot')\n",
    "plot(spotlist.y, 20*correction[5,:], label='20X Correction')\n",
    "legend(loc='center right', bbox_to_anchor=(2.0, 0.5))\n",
    "subplot(2,3,4)\n",
    "title(\"Spot\")\n",
    "imshow(spot, interpolation = 'nearest')\n",
    "subplot(2,3,5)\n",
    "title(\"NewSpot\")\n",
    "imshow(newspot, interpolation = 'nearest')\n",
    "subplot(2,3,6)\n",
    "title(\"Correction\")\n",
    "imshow(correction, interpolation = 'nearest')\n",
    "colorbar()\n",
    "#show()\n",
    "savefig(datadir+\"Coulton_Correction_Model_Central_CSteps_7_07Jun18.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the correction implementation on a single spotlist\n",
    "figure(figsize=(16,8))\n",
    "subplots_adjust(wspace=0.5)\n",
    "\n",
    "gain = 4.40\n",
    "for spot in range(spotlist.nstamps):\n",
    "    newspot = copy(gain * spotlist.data[:,:,spot])\n",
    "    correction = zeros(newspot.shape)\n",
    "    diff = 100.0\n",
    "    numsteps = 0\n",
    "    # Iterate to convergence\n",
    "    while diff > 1.0E-6:\n",
    "        lastcorrection = copy(correction)\n",
    "        correction = Correction(newspot, kernel.kernel)\n",
    "        newspot = gain * spotlist.data[:,:,spot] + correction\n",
    "        diff = ((lastcorrection - correction) * (lastcorrection - correction)).sum()\n",
    "        #print \"Diff = %f\"%diff\n",
    "        numsteps += 1\n",
    "    if spot % 100 == 0:\n",
    "        print \"Finished spot %d, Numsteps to converge = %d, Correction Sum = %f\"\\\n",
    "        %(spot,numsteps, correction.sum()) \n",
    "    \n",
    "    if spot == spotlist.nstamps - 1:  # Plot the last one, with correction\n",
    "        subplot(2,3,1)\n",
    "        title(\"X\")\n",
    "        plot(spotlist.x, spotlist.data[:,5,-1] * gain, label='Spot')\n",
    "        plot(spotlist.x, newspot[:,5], label='NewSpot')\n",
    "        plot(spotlist.x, 20*correction[:,5], label='20X Correction')\n",
    "        subplot(2,3,2)\n",
    "        title(\"Y\")\n",
    "        plot(spotlist.y, spotlist.data[5,:,-1] * gain, label='Spot')\n",
    "        plot(spotlist.y, newspot[5,:], label='NewSpot')\n",
    "        plot(spotlist.y, 20*correction[5,:], label='20X Correction')\n",
    "        legend(loc='center right', bbox_to_anchor=(2.0, 0.5))\n",
    "        subplot(2,3,4)\n",
    "        title(\"Spot\")\n",
    "        imshow(spotlist.data[:,:,-1] * gain, interpolation = 'nearest')\n",
    "        subplot(2,3,5)\n",
    "        title(\"NewSpot\")\n",
    "        imshow(newspot, interpolation = 'nearest')\n",
    "        subplot(2,3,6)\n",
    "        title(\"Correction\")\n",
    "        imshow(correction, interpolation = 'nearest')\n",
    "        colorbar()\n",
    "\n",
    "    for i in range(spotlist.nx):\n",
    "        for j in range(spotlist.ny):\n",
    "            spotlist.data[i,j,spot] = newspot[i,j] / gain\n",
    "\n",
    "args = ()#(spotlist)\n",
    "param0 = [1.0, 1.0, 1.0]\n",
    "Result = fmin_powell(FOM, param0, args)\n",
    "print \"Old Sigmas = \", OldResult,\"New Sigmas = \", Result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try it with a full list of spots on two segments\n",
    "import gc\n",
    "nx = 11\n",
    "ny = 11\n",
    "numspots = 400\n",
    "numfiles = len(zfilelist)\n",
    "sigmaxs = zeros([1,numfiles])\n",
    "sigmays = zeros([1,numfiles])\n",
    "imaxs = zeros([1,numfiles])\n",
    "totelectrons = zeros([1,numfiles])\n",
    "corr_sigmaxs = zeros([1,numfiles])\n",
    "corr_sigmays = zeros([1,numfiles])\n",
    "corr_imaxs = zeros([1,numfiles])\n",
    "corr_totelectrons = zeros([1,numfiles])\n",
    "\n",
    "gains = [4.40]\n",
    "\n",
    "for i, segmentnumber in enumerate([1]):\n",
    "    gain = gains[i]\n",
    "\n",
    "    for j,fitsfilename in enumerate(zfilelist):\n",
    "\n",
    "        # First run the forward modeling on the uncorrected spotlist\n",
    "        param0 = [1.0, 1.0, 1.0]\n",
    "        spotlist = BuildSpotList(fitsfilename, segmentnumber, numspots, nx, ny,0.7,2.0)\n",
    "        print \"nstamps = %d\"%spotlist.nstamps\n",
    "        args = ()\n",
    "        Result = fmin_powell(FOM, param0, args)\n",
    "\n",
    "        print fitsfilename\n",
    "        imax = spotlist.imax.mean()\n",
    "        ADU_correction = Area(-0.5,0.5,-0.5,0.5,Result[0],Result[1],1.0)\n",
    "        tote = spotlist.data.sum() * gain / spotlist.nstamps # Total electrons in the stamp\n",
    "        print \"Uncorrected:\",Result, imax, tote\n",
    "        imaxs[i,j] = imax * ADU_correction * gain\n",
    "        sigmaxs[i,j] = abs(Result[0])\n",
    "        sigmays[i,j] = abs(Result[1])\n",
    "        totelectrons[i,j] = tote\n",
    "\n",
    "        # Now apply the correction and recalculate the forward modeling\n",
    "        for spot in range(spotlist.nstamps):\n",
    "            newspot = copy(gain * spotlist.data[:,:,spot])\n",
    "            correction = zeros(newspot.shape)\n",
    "            diff = 100.0\n",
    "            numsteps = 0\n",
    "            # Iterate to convergence\n",
    "            while diff > 1.0E-6:\n",
    "                lastcorrection = copy(correction)\n",
    "                correction = Correction(newspot, kernel.kernel) \n",
    "                newspot = gain * spotlist.data[:,:,spot] + correction\n",
    "                diff = ((lastcorrection - correction) * (lastcorrection - correction)).sum()\n",
    "                #print \"Diff = %f\"%diff\n",
    "                numsteps += 1\n",
    "            for ii in range(spotlist.nx):\n",
    "                for jj in range(spotlist.ny):\n",
    "                    spotlist.data[ii,jj,spot] = newspot[ii,jj] / gain\n",
    "            if spot % 100 == 0:\n",
    "                print \"Finished spot %d, Numsteps to converge = %d\"%(spot, numsteps)\n",
    "        args = ()\n",
    "        param0 = [1.0, 1.0, 1.0]\n",
    "        Result = fmin_powell(FOM, param0, args)\n",
    "        imax = spotlist.imax.mean()\n",
    "        ADU_correction = Area(-0.5,0.5,-0.5,0.5,Result[0],Result[1],1.0)\n",
    "        tote = spotlist.data.sum() * gain / spotlist.nstamps # Total electrons in the stamp\n",
    "        print \"Corrected\",Result, imax, tote\n",
    "        corr_imaxs[i,j] = imax * ADU_correction * gain\n",
    "        corr_sigmaxs[i,j] = abs(Result[0])\n",
    "        corr_sigmays[i,j] = abs(Result[1])\n",
    "        corr_totelectrons[i,j] = tote\n",
    "        del spotlist\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the result\n",
    "rcParams.update({'font.size':10})\n",
    "# The following masks out bad fits files of undetermined cause, probably due to the shutter sticking\n",
    "mask = []\n",
    "\n",
    "for i, segmentnumber in enumerate([1]):\n",
    "    hdr=pf.getheader(zfilelist[0],segmentnumber)\n",
    "    extname = hdr['EXTNAME']\n",
    "\n",
    "    figure()\n",
    "    title(\"Brighter-Fatter - 30 micron Spots - %s\"%extname)\n",
    "    # First plot the uncorrected data\n",
    "    scatter(delete(imaxs[i,:],mask), delete(sigmaxs[i,:],mask), color = 'green', lw = 2, label = 'Sigma-x')\n",
    "    scatter(delete(imaxs[i,:],mask), delete(sigmays[i,:],mask), color = 'red', lw = 2, label = 'Sigma-y')\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(imaxs[i,:],sigmaxs[i,:])\n",
    "    xplot=linspace(-5000.0,300000.0,100)\n",
    "    yplot = slope * xplot + intercept\n",
    "    plot(xplot, yplot, color='green', lw = 2, ls = '--')\n",
    "    tslope = slope * 100.0 * 50000.0\n",
    "    text(10000.0,1.09,\"X Slope = %.2f %% per 50K e-, Intercept = %.3f\"%(tslope,intercept), fontsize=10)\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(imaxs[i,:],sigmays[i,:])\n",
    "    xplot=linspace(-5000.0,300000.0,100)\n",
    "    yplot = slope * xplot + intercept\n",
    "    plot(xplot, yplot, color='red', lw = 2, ls = '--')\n",
    "    tslope = slope * 100.0 * 50000.0\n",
    "    text(10000.0,1.082,\"Y Slope = %.2f %% per 50K e-, Intercept = %.3f\"%(tslope,intercept), fontsize=10)\n",
    "\n",
    "    # Now plot the corrected data\n",
    "    scatter(delete(corr_imaxs[i,:],mask), delete(corr_sigmaxs[i,:],mask), color = 'cyan', lw = 2, marker = 'x',label = 'Corrected Sigma-x')\n",
    "    scatter(delete(corr_imaxs[i,:],mask), delete(corr_sigmays[i,:],mask), color = 'magenta', lw = 2, marker = 'x', label = 'Corrected Sigma-y')\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(corr_imaxs[i,:],corr_sigmaxs[i,:])\n",
    "    xplot=linspace(-5000.0,300000.0,100)\n",
    "    yplot = slope * xplot + intercept\n",
    "    plot(xplot, yplot, color='cyan', lw = 2, ls = '--')\n",
    "    tslope = slope * 100.0 * 50000.0\n",
    "    text(10000.0,1.074,\"Corrected X Slope = %.2f %% per 50K e-, Intercept = %.3f\"%(tslope,intercept), fontsize=10)\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(corr_imaxs[i,:],corr_sigmays[i,:])\n",
    "    xplot=linspace(-5000.0,300000.0,100)\n",
    "    yplot = slope * xplot + intercept\n",
    "    plot(xplot, yplot, color='magenta', lw = 2, ls = '--')\n",
    "    tslope = slope * 100.0 * 50000.0\n",
    "    text(10000.0,1.066,\"Corrected Y Slope = %.2f %% per 50K e-, Intercept = %.3f\"%(tslope,intercept), fontsize=10)\n",
    "\n",
    "    xlim(0.0,150000.0)\n",
    "    xticks([0,50000,100000])\n",
    "    ylim(1.00,1.10)\n",
    "    xlabel('Central Peak(electrons)')\n",
    "    ylabel('Sigma (Pixels)')\n",
    "    legend(loc= 'lower right',fontsize = 9)#, bbox_to_anchor=[1.8,-0.1])\n",
    "    savefig(datadir+'Forward_Model_Central_CSteps_7_%s_07Jun18.pdf'%extname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,8))\n",
    "title(\"Flux Lost in BF Kernel Correction\")\n",
    "for i, segmentnumber in enumerate([1]):\n",
    "    hdr=pf.getheader(zfilelist[0],segmentnumber)\n",
    "    extname = hdr['EXTNAME']\n",
    "    flux_loss = (totelectrons[i,:] - corr_totelectrons[i,:]) / totelectrons[i,:] * 100.0\n",
    "    print extname, flux_loss.max(), flux_loss.min()\n",
    "    plot(imaxs[i,:], flux_loss, label = extname)\n",
    "\n",
    "    xlim(0.0,300000.0)\n",
    "    xticks([0,100000,200000])\n",
    "    ylim(-0.5,0.1)\n",
    "    xlabel('Central Peak(electrons)')\n",
    "    ylabel('Flux Loss (%)')\n",
    "legend(loc='lower right')\n",
    "savefig(datadir+'Flux_Loss_Model_Rot_CSteps_7_05Jun18.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
