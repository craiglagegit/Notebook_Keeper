{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cc3a14-f377-44f4-ab4c-97c9c3047697",
   "metadata": {},
   "source": [
    "# Fourier transform of mount errors\n",
    "\n",
    "Craig Lage - 27-Nov-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148b369-8943-4861-a51e-9cbeea70feb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:21:32.350002Z",
     "iopub.status.busy": "2024-01-02T14:21:32.349798Z",
     "iopub.status.idle": "2024-01-02T14:21:39.571787Z",
     "shell.execute_reply": "2024-01-02T14:21:39.571319Z",
     "shell.execute_reply.started": "2024-01-02T14:21:32.349989Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import sys, time, os, asyncio\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.daf.butler import Butler\n",
    "\n",
    "import lsst.summit.utils.butlerUtils as butlerUtils\n",
    "from lsst.summit.utils.utils import dayObsIntToString\n",
    "from astro_metadata_translator import ObservationInfo\n",
    "from lsst_efd_client import merge_packed_time_series as mpts\n",
    "from scipy.interpolate import UnivariateSpline, LSQUnivariateSpline\n",
    "\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b3867-c6db-43d3-8248-ecfcd41d3fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T11:48:46.233269Z",
     "iopub.status.busy": "2023-12-30T11:48:46.232969Z",
     "iopub.status.idle": "2023-12-30T11:48:47.951889Z",
     "shell.execute_reply": "2023-12-30T11:48:47.951448Z",
     "shell.execute_reply.started": "2023-12-30T11:48:46.233256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = EfdClient('idf_efd')\n",
    "old_butler = Butler('/repo/main', collections=\"LATISS/raw/all\")\n",
    "new_butler = Butler('/repo/embargo', collections=\"LATISS/raw/all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adebfb-5a29-4f8a-9336-bc9c19bef499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T11:48:47.952967Z",
     "iopub.status.busy": "2023-12-30T11:48:47.952832Z",
     "iopub.status.idle": "2023-12-30T11:48:47.955811Z",
     "shell.execute_reply": "2023-12-30T11:48:47.955446Z",
     "shell.execute_reply.started": "2023-12-30T11:48:47.952954Z"
    }
   },
   "outputs": [],
   "source": [
    "NON_TRACKING_IMAGE_TYPES = ['BIAS',\n",
    "                            'FLAT',\n",
    "                            ]\n",
    "\n",
    "AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC = 280.0\n",
    "MOUNT_IMAGE_WARNING_LEVEL = .25  # this determines the colouring of the cells in the table, yellow for this\n",
    "MOUNT_IMAGE_BAD_LEVEL = .4\n",
    "\n",
    "\n",
    "def _getEfdData(client, dataSeries, startTime, endTime):\n",
    "    \"\"\"A synchronous warpper for geting the data from the EFD.\n",
    "\n",
    "    This exists so that the top level functions don't all have to be async def.\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(client.select_time_series(dataSeries, ['*'], startTime.utc, endTime.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144407b9-d66c-481f-aac1-cf1cc01754b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T11:48:47.956411Z",
     "iopub.status.busy": "2023-12-30T11:48:47.956289Z",
     "iopub.status.idle": "2023-12-30T11:48:47.961388Z",
     "shell.execute_reply": "2023-12-30T11:48:47.961031Z",
     "shell.execute_reply.started": "2023-12-30T11:48:47.956399Z"
    }
   },
   "outputs": [],
   "source": [
    "def findSpline(xf, yf, numKnots=18):\n",
    "    s1 = 1; s2 = 1.0E7\n",
    "    spline = UnivariateSpline(xf, yf, s=s1)\n",
    "    knots = spline.get_knots()\n",
    "    if len(knots) < numKnots:\n",
    "        return s1, knots\n",
    "    count = 0\n",
    "    while count < 50:\n",
    "        count += 1\n",
    "        s = np.sqrt(s1 * s2)\n",
    "        spline = UnivariateSpline(xf, yf, s=s)\n",
    "        knots = spline.get_knots()\n",
    "        if len(knots) > numKnots:\n",
    "            s1 = s\n",
    "        else:\n",
    "            s2 = s\n",
    "        if abs(len(knots) - numKnots) < 2:\n",
    "            return s, knots\n",
    "    return s,knots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29298ea-cb53-4a53-accb-0d59956745c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFFTPeaks(dataId, butler, client, limit=0.25):\n",
    "\n",
    "    expRecord = butlerUtils.getExpRecordFromDataId(butler, dataId)\n",
    "    dayString = dayObsIntToString(expRecord.day_obs)\n",
    "    seqNumString = str(expRecord.seq_num)\n",
    "    dataIdString = f\"{dayString} - seqNum {seqNumString}\"\n",
    "\n",
    "    imgType = expRecord.observation_type.upper()\n",
    "    if imgType in NON_TRACKING_IMAGE_TYPES:\n",
    "        return False\n",
    "\n",
    "    exptime = expRecord.exposure_time\n",
    "    if exptime < 1.99:\n",
    "        return False\n",
    "\n",
    "    tStart = expRecord.timespan.begin.tai.to_value(\"isot\")\n",
    "    tEnd = expRecord.timespan.end.tai.to_value(\"isot\")\n",
    "    elevation = 90.0 - expRecord.zenith_angle\n",
    "\n",
    "    # TODO: DM-33859 remove this once it can be got from the expRecord\n",
    "    md = butler.get('raw.metadata', dataId, detector=0)\n",
    "    obsInfo = ObservationInfo(md)\n",
    "    azimuth = obsInfo.altaz_begin.az.value\n",
    "    # Time base in the EFD is still a big mess.  Although these times are in\n",
    "    # UTC, it is necessary to tell the code they are in TAI. Then it is\n",
    "    # necessary to tell the merge_packed_time_series to use UTC.\n",
    "    # After doing all of this, there is still a 2 second offset,\n",
    "    # which is discussed in JIRA ticket DM-29243, but not understood.\n",
    "\n",
    "    t_start = Time(tStart, scale='tai')\n",
    "    t_end = Time(tEnd, scale='tai')\n",
    "\n",
    "    mount_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_AzEl_Encoders\", t_start, t_end)\n",
    "    nasmyth_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_Nasmyth_Encoders\", t_start, t_end)\n",
    "    torques = _getEfdData(client, \"lsst.sal.ATMCS.measuredTorque\", t_start, t_end)\n",
    "\n",
    "    az = mpts(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "    el = mpts(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "    rot = mpts(nasmyth_position, 'nasmyth2CalculatedAngle', stride=1)\n",
    "    az_torque_1 = mpts(torques, 'azimuthMotor1Torque', stride=1)\n",
    "    az_torque_2 = mpts(torques, 'azimuthMotor2Torque', stride=1)\n",
    "    el_torque = mpts(torques, 'elevationMotorTorque', stride=1)\n",
    "    rot_torque = mpts(torques, 'nasmyth2MotorTorque', stride=1)\n",
    "\n",
    "    # Calculate the tracking errors\n",
    "    az_vals = np.array(az.values[:, 0])\n",
    "    el_vals = np.array(el.values[:, 0])\n",
    "    rot_vals = np.array(rot.values[:, 0])\n",
    "    times = np.array(az.values[:, 1])\n",
    "    # The fits are much better if the time variable\n",
    "    # is centered in the interval\n",
    "    fit_times = times - times[int(len(az.values[:, 1]) / 2)]\n",
    "\n",
    "    # Fit with a polynomial\n",
    "    az_fit = np.polyfit(fit_times, az_vals, 4)\n",
    "    el_fit = np.polyfit(fit_times, el_vals, 4)\n",
    "    rot_fit = np.polyfit(fit_times, rot_vals, 2)\n",
    "    az_model = np.polyval(az_fit, fit_times)\n",
    "    el_model = np.polyval(el_fit, fit_times)\n",
    "    rot_model = np.polyval(rot_fit, fit_times)\n",
    "\n",
    "    # Errors in arcseconds\n",
    "    az_error = (az_vals - az_model) * 3600\n",
    "    el_error = (el_vals - el_model) * 3600\n",
    "    rot_error = (rot_vals - rot_model) * 3600\n",
    "\n",
    "    # Calculate RMS\n",
    "    az_rms = np.sqrt(np.mean(az_error * az_error))\n",
    "    el_rms = np.sqrt(np.mean(el_error * el_error))\n",
    "    rot_rms = np.sqrt(np.mean(rot_error * rot_error))\n",
    "\n",
    "    # Calculate Image impact RMS\n",
    "    image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)\n",
    "    image_el_rms = el_rms\n",
    "    image_rot_rms = rot_rms * AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC * np.pi / 180.0 / 3600.0\n",
    "    tot_rms = np.sqrt(image_az_rms**2 + image_el_rms**2 + image_rot_rms**2)\n",
    "\n",
    "    if tot_rms < limit:\n",
    "        return False\n",
    "    else:\n",
    "        # Calculate the FFT peaks\n",
    "        fft_peaks = []\n",
    "        for i, error in enumerate([az_error, el_error]):\n",
    "            # Number of samples in normalized_tone\n",
    "            N = len(error)\n",
    "            SAMPLE_RATE = 100 # Samples/sec\n",
    "            \n",
    "            yf = fft(error)\n",
    "            yf = yf[0:int(len(az_error)/2)]\n",
    "            xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "            xf = xf[0:int(len(error)/2)]\n",
    "            yf = np.abs(fft(error))\n",
    "            yf = yf[0:int(len(error)/2)]\n",
    "            max = np.max(yf)\n",
    "            peak_indices, peak_dict = find_peaks(yf, height=max/100) \n",
    "            peak_heights = peak_dict['peak_heights']\n",
    "            \n",
    "            for j in range(1,4):\n",
    "                peak_index = peak_indices[np.argpartition(peak_heights,-j)[-j]]\n",
    "                peak_freq = xf[peak_index]\n",
    "                height_index = np.where(peak_indices == peak_index)[0][0]\n",
    "                peak_height = peak_heights[height_index]\n",
    "                fft_peaks.append([peak_freq, peak_height])\n",
    "    return [tot_rms, fft_peaks]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861d0d3-e7f0-49b1-bc2f-8fe290e4edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFFTKnots(dataId, butler, client, limit=0.25):\n",
    "    expRecord = butlerUtils.getExpRecordFromDataId(butler, dataId)\n",
    "    dayString = dayObsIntToString(expRecord.day_obs)\n",
    "    seqNumString = str(expRecord.seq_num)\n",
    "    dataIdString = f\"{dayString} - seqNum {seqNumString}\"\n",
    "\n",
    "    imgType = expRecord.observation_type.upper()\n",
    "    if imgType in NON_TRACKING_IMAGE_TYPES:\n",
    "        return False\n",
    "\n",
    "    exptime = expRecord.exposure_time\n",
    "    if exptime < 4.99:\n",
    "        return False\n",
    "\n",
    "    tStart = expRecord.timespan.begin.tai.to_value(\"isot\")\n",
    "    tEnd = expRecord.timespan.end.tai.to_value(\"isot\")\n",
    "    elevation = 90.0 - expRecord.zenith_angle\n",
    "\n",
    "    # TODO: DM-33859 remove this once it can be got from the expRecord\n",
    "    md = butler.get('raw.metadata', dataId, detector=0)\n",
    "    obsInfo = ObservationInfo(md)\n",
    "    azimuth = obsInfo.altaz_begin.az.value\n",
    "\n",
    "    t_start = Time(tStart, scale='tai')\n",
    "    t_end = Time(tEnd, scale='tai')\n",
    "\n",
    "    mount_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_AzEl_Encoders\", t_start, t_end)\n",
    "\n",
    "    az = mpts(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "    el = mpts(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "\n",
    "    # Calculate the tracking errors\n",
    "    az_vals = np.array(az.values[:, 0])\n",
    "    el_vals = np.array(el.values[:, 0])\n",
    "    times = np.array(az.values[:, 1])\n",
    "    # The fits are much better if the time variable\n",
    "    # is centered in the interval\n",
    "    fit_times = times - times[int(len(az.values[:, 1]) / 2)]\n",
    "\n",
    "    # Fit with a polynomial\n",
    "    az_fit = np.polyfit(fit_times, az_vals, 4)\n",
    "    el_fit = np.polyfit(fit_times, el_vals, 4)\n",
    "    az_model = np.polyval(az_fit, fit_times)\n",
    "    el_model = np.polyval(el_fit, fit_times)\n",
    "\n",
    "    # Errors in arcseconds\n",
    "    az_error = (az_vals - az_model) * 3600\n",
    "    el_error = (el_vals - el_model) * 3600\n",
    "\n",
    "    # Calculate RMS\n",
    "    az_rms = np.sqrt(np.mean(az_error * az_error))\n",
    "    el_rms = np.sqrt(np.mean(el_error * el_error))\n",
    "    rot_rms = np.sqrt(np.mean(rot_error * rot_error))\n",
    "\n",
    "    # Calculate Image impact RMS\n",
    "    image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)\n",
    "    image_el_rms = el_rms\n",
    "    image_rot_rms = rot_rms * AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC * np.pi / 180.0 / 3600.0\n",
    "    tot_rms = np.sqrt(image_az_rms**2 + image_el_rms**2 + image_rot_rms**2)\n",
    "\n",
    "    if tot_rms < limit:\n",
    "        return [tot_rms, None]\n",
    "    else:\n",
    "        # Calculate the FFT knots\n",
    "        numKnots = 18\n",
    "        knotList = []\n",
    "        for i, error in enumerate([az_error, el_error]):\n",
    "            # Number of samples in normalized_tone\n",
    "            N = len(error)\n",
    "            SAMPLE_RATE = 100 # Samples/sec\n",
    "            yf = fft(error)\n",
    "            xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "            yf = np.abs(fft(error))\n",
    "            # Truncate the FFT above 5 Hz\n",
    "            count = 0\n",
    "            for n in range(len(xf)):\n",
    "                if xf[n] < 5.0:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "            xf = xf[0:count]\n",
    "            yf = yf[0:count]\n",
    "\n",
    "            s, knots = findSpline(xf, yf, numKnots=numKnots)\n",
    "            spline = UnivariateSpline(xf, yf, s=s)\n",
    "            knots = spline.get_knots()\n",
    "            values = spline(knots)\n",
    "            if len(knots) < numKnots:\n",
    "                numToAdd = int(numKnots - len(knots))\n",
    "                lenKnots = knots[-1] - knots[0]\n",
    "                for n in range(numToAdd):\n",
    "                    newKnot = knots[-1] + 0.01 * (n+1)\n",
    "                    newValue = values[-1]\n",
    "                    knots = np.append(knots, newKnot)\n",
    "                    values = np.append(values, newValue)\n",
    "            if len(knots) > numKnots:\n",
    "                knots = np.delete(knots, [-2])\n",
    "                values = np.delete(values, [-2])\n",
    "            for n in range(numKnots):\n",
    "                knotList.append(knots[n])\n",
    "                knotList.append(values[n])\n",
    "\n",
    "        return [tot_rms, knotList]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81384103-ec82-47e4-9f7e-0820a6bda2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrorPeaks(dataId, butler, client, limit=0.25):\n",
    "\n",
    "    expRecord = butlerUtils.getExpRecordFromDataId(butler, dataId)\n",
    "    dayString = dayObsIntToString(expRecord.day_obs)\n",
    "    seqNumString = str(expRecord.seq_num)\n",
    "    dataIdString = f\"{dayString} - seqNum {seqNumString}\"\n",
    "\n",
    "    imgType = expRecord.observation_type.upper()\n",
    "    if imgType in NON_TRACKING_IMAGE_TYPES:\n",
    "        return False\n",
    "\n",
    "    exptime = expRecord.exposure_time\n",
    "    if exptime < 1.99:\n",
    "        return False\n",
    "\n",
    "    tStart = expRecord.timespan.begin.tai.to_value(\"isot\")\n",
    "    tEnd = expRecord.timespan.end.tai.to_value(\"isot\")\n",
    "    elevation = 90.0 - expRecord.zenith_angle\n",
    "\n",
    "    # TODO: DM-33859 remove this once it can be got from the expRecord\n",
    "    md = butler.get('raw.metadata', dataId, detector=0)\n",
    "    obsInfo = ObservationInfo(md)\n",
    "    azimuth = obsInfo.altaz_begin.az.value\n",
    "    # Time base in the EFD is still a big mess.  Although these times are in\n",
    "    # UTC, it is necessary to tell the code they are in TAI. Then it is\n",
    "    # necessary to tell the merge_packed_time_series to use UTC.\n",
    "    # After doing all of this, there is still a 2 second offset,\n",
    "    # which is discussed in JIRA ticket DM-29243, but not understood.\n",
    "\n",
    "    t_start = Time(tStart, scale='tai')\n",
    "    t_end = Time(tEnd, scale='tai')\n",
    "\n",
    "    mount_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_AzEl_Encoders\", t_start, t_end)\n",
    "    nasmyth_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_Nasmyth_Encoders\", t_start, t_end)\n",
    "    torques = _getEfdData(client, \"lsst.sal.ATMCS.measuredTorque\", t_start, t_end)\n",
    "\n",
    "    az = mpts(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "    el = mpts(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "    rot = mpts(nasmyth_position, 'nasmyth2CalculatedAngle', stride=1)\n",
    "    az_torque_1 = mpts(torques, 'azimuthMotor1Torque', stride=1)\n",
    "    az_torque_2 = mpts(torques, 'azimuthMotor2Torque', stride=1)\n",
    "    el_torque = mpts(torques, 'elevationMotorTorque', stride=1)\n",
    "    rot_torque = mpts(torques, 'nasmyth2MotorTorque', stride=1)\n",
    "\n",
    "    # Calculate the tracking errors\n",
    "    az_vals = np.array(az.values[:, 0])\n",
    "    el_vals = np.array(el.values[:, 0])\n",
    "    rot_vals = np.array(rot.values[:, 0])\n",
    "    times = np.array(az.values[:, 1])\n",
    "    # The fits are much better if the time variable\n",
    "    # is centered in the interval\n",
    "    fit_times = times - times[int(len(az.values[:, 1]) / 2)]\n",
    "\n",
    "    # Fit with a polynomial\n",
    "    az_fit = np.polyfit(fit_times, az_vals, 4)\n",
    "    el_fit = np.polyfit(fit_times, el_vals, 4)\n",
    "    rot_fit = np.polyfit(fit_times, rot_vals, 2)\n",
    "    az_model = np.polyval(az_fit, fit_times)\n",
    "    el_model = np.polyval(el_fit, fit_times)\n",
    "    rot_model = np.polyval(rot_fit, fit_times)\n",
    "\n",
    "    # Errors in arcseconds\n",
    "    az_error = (az_vals - az_model) * 3600\n",
    "    el_error = (el_vals - el_model) * 3600\n",
    "    rot_error = (rot_vals - rot_model) * 3600\n",
    "\n",
    "    # Calculate RMS\n",
    "    az_rms = np.sqrt(np.mean(az_error * az_error))\n",
    "    el_rms = np.sqrt(np.mean(el_error * el_error))\n",
    "    rot_rms = np.sqrt(np.mean(rot_error * rot_error))\n",
    "\n",
    "    # Calculate Image impact RMS\n",
    "    image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)\n",
    "    image_el_rms = el_rms\n",
    "    image_rot_rms = rot_rms * AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC * np.pi / 180.0 / 3600.0\n",
    "    tot_rms = np.sqrt(image_az_rms**2 + image_el_rms**2 + image_rot_rms**2)\n",
    "\n",
    "    if tot_rms < limit:\n",
    "        return False\n",
    "    else:\n",
    "        # Calculate the error peaks\n",
    "        error_peaks = []\n",
    "        for i, error in enumerate([az_error, el_error]):\n",
    "            max = np.max(error)\n",
    "            peak_indices, peak_dict = find_peaks(error, height=max/100) \n",
    "            peak_heights = peak_dict['peak_heights']\n",
    "            print(i, len(error), peak_indices, peak_heights)\n",
    "            \"\"\"\n",
    "            for j in range(1,4):\n",
    "                peak_index = peak_indices[np.argpartition(peak_heights,-j)[-j]]\n",
    "                peak_freq = xf[peak_index]\n",
    "                height_index = np.where(peak_indices == peak_index)[0][0]\n",
    "                peak_height = peak_heights[height_index]\n",
    "                fft_peaks.append([peak_freq, peak_height])\n",
    "            \"\"\"\n",
    "    return \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6969f-6472-4b27-aa58-fdfe52a83be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expId = 2023110800415 # Oscillation\n",
    "#expId = 2023111600552 # Wind\n",
    "expId = 2023111600561 # Crazy mount?\n",
    "#expId = 2023112000238 # Crazy mount?\n",
    "#expId = 2023112000201 # Shutter open too soon\n",
    "#expId = 2023110700594 # Timebase errors 1\n",
    "#expId = 2023110700519 # Timebase errors 2\n",
    "dataId = {'detector':0, 'exposure':expId}\n",
    "[tot_rms, knotList] = calculateFFTKnots(dataId, new_butler, client)\n",
    "print(knotList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4929cd-9012-4f5b-bf1b-02814052852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayObs_list = [20221110, 20221212, 20230118, 20230216, \\\n",
    "               20220315, 20230511, 20230817, 20231107, 20231113, 20231121, 20231128, 20231129, 20231130]\n",
    "\n",
    "Mount_FFT_Dict = {}\n",
    "for dayObs in dayObs_list:\n",
    "    if dayObs < 20220915:\n",
    "        butler = old_butler\n",
    "    else:\n",
    "        butler = new_butler\n",
    "\n",
    "    exposureList = []\n",
    "\n",
    "    for record in butler.registry.queryDimensionRecords(\"exposure\", where=\"exposure.day_obs=%d\"%dayObs):\n",
    "        if record.observation_type not in ['bias', 'flat', 'dark']:\n",
    "            exposureList.append(record.id)\n",
    "    exposureList = sorted(exposureList)\n",
    "\n",
    "    for expId in exposureList:\n",
    "        try:\n",
    "            dataId = {'detector':0, 'exposure':expId}\n",
    "            result = calculateFFTKnots(dataId, butler, client)\n",
    "            #print(expId, result)\n",
    "            if result:\n",
    "                [tot_rms, fftKnots] = result\n",
    "                resDict = {}\n",
    "                resDict['Cause'] = None\n",
    "                resDict['RMS'] = tot_rms\n",
    "                resDict['FFT_knots'] = fftKnots\n",
    "                Mount_FFT_Dict[expId] = resDict\n",
    "                print(f\"Finished {expId}\")\n",
    "        except:\n",
    "            continue\n",
    "    outfile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Knots.pkl', 'wb')\n",
    "\n",
    "    pkl.dump(Mount_FFT_Dict,outfile)\n",
    "    outfile.close()\n",
    "    print(f\"Finished {dayObs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2230d4-6e2c-44a2-8613-b46da3f1d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Knots.pkl', 'rb')\n",
    "Mount_FFT_Dict = pkl.load(infile)\n",
    "infile.close()\n",
    "print(list(Mount_FFT_Dict.keys())[-1])\n",
    "print(len(list(Mount_FFT_Dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78203c-67b5-4eb3-9198-abbaa831b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for expId in list(Mount_FFT_Dict.keys()):\n",
    "    if len(Mount_FFT_Dict[expId]['FFT_knots']) != 72:\n",
    "        print(expId, len(Mount_FFT_Dict[expId]['FFT_knots']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c6596-1c1d-4832-9218-d16c00382ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict.pkl', 'rb')\n",
    "Mount_FFT_Dict = pkl.load(infile)\n",
    "Mount_FFT_Dict_Classified = Mount_FFT_Dict.copy()\n",
    "infile.close()\n",
    "outfile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Classified.pkl', 'wb')\n",
    "pkl.dump(Mount_FFT_Dict_Classified,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f46396-6c03-4b28-a970-756868c01896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Classified.pkl', 'rb')\n",
    "Mount_FFT_Dict_Classified = pkl.load(infile)\n",
    "infile.close()\n",
    "causes = ['OSC', 'WIN', 'CRA', 'TIM', 'SHU']\n",
    "\n",
    "print(causes)\n",
    "for key in Mount_FFT_Dict_Classified.keys():\n",
    "    year = int(key/1000000000)\n",
    "    month = int((key - 1000000000 * year)/10000000)\n",
    "    day = int((key - 1000000000 * year - 10000000 * month)/100000)\n",
    "    seqNum = int((key - 1000000000 * year - 10000000 * month - 100000 * day))\n",
    "\n",
    "    if Mount_FFT_Dict_Classified[key]['Cause'] is None:\n",
    "        webbrowser.open(f'https://roundtable.lsst.codes/rubintv/summit/auxtel/mount/event/{year}-{month:02}-{day:02}/{seqNum}')\n",
    "        break\n",
    "        cause = input(f\"Classification of {key}\")\n",
    "        if cause == 'STOP':\n",
    "            break\n",
    "        else:\n",
    "            Mount_FFT_Dict_Classified[key]['Cause'] = cause\n",
    "\n",
    "outfile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Classified.pkl', 'wb')\n",
    "pkl.dump(Mount_FFT_Dict_Classified,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d48b99-a5f5-4a12-bf97-f33ea1358907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "webbrowser.open('http://example.com')\n",
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_FFT_Dict_Classified.pkl', 'rb')\n",
    "Mount_FFT_Dict_Classified = pkl.load(infile)\n",
    "infile.close()\n",
    "causes = ['OSC', 'WIN', 'CRA', 'TIM', 'SHU']\n",
    "\n",
    "print(causes)\n",
    "for key in Mount_FFT_Dict_Classified.keys():\n",
    "    print(key, Mount_FFT_Dict_Classified[key]['Cause'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935eb593-6f96-444a-b070-4903e1e5912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mount_FFT_Dict[2022111000353]['Cause'] is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47682690-fd3a-4cc7-811e-f0b8467c5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Mount_FFT_Dict_Classified[2022111000235].keys():\n",
    "    print(key, Mount_FFT_Dict_Classified[2022111000235][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fe871-2625-4b7a-9f55-cd0752f38537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Mount_FFT_Dict_Classified.keys():\n",
    "    year = int(key/1000000000)\n",
    "    month = int((key - 1000000000 * year)/10000000)\n",
    "    day = int((key - 1000000000 * year - 10000000 * month)/100000)\n",
    "    seqNum = int((key - 1000000000 * year - 10000000 * month - 100000 * day))\n",
    "    print(year, month, day, seqNum)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811d58b-13c3-4483-8a15-848b8d8634f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://roundtable.lsst.codes/rubintv/summit/auxtel/mount/event/{year}-{month:02}-{day:02}/{seqNum}'\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4eba77-044f-499d-abad-ee2d76f893bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'https://roundtable.lsst.codes/rubintv/summit/auxtel/mount/event/{year}-{month:02}-{day:02}/{seqNum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c438844-8e83-4621-bb5f-d2719fbf0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser._browsers.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236836f8-00ec-49e7-8321-6f482ed30a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T12:01:33.490068Z",
     "iopub.status.busy": "2023-12-30T12:01:33.489557Z",
     "iopub.status.idle": "2023-12-30T12:01:34.988068Z",
     "shell.execute_reply": "2023-12-30T12:01:34.987574Z",
     "shell.execute_reply.started": "2023-12-30T12:01:33.490039Z"
    }
   },
   "outputs": [],
   "source": [
    "#expId = 2023110800415 # Oscillation\n",
    "#expId = 2023111600552 # Wind\n",
    "#expId = 2023111600561 # Crazy mount?\n",
    "#expId = 2023112000238 # Crazy mount?\n",
    "expId = 2023112000201 # Shutter open too soon\n",
    "expId = 2023113000629 # Shutter open too soon\n",
    "#expId = 2023110700594 # Timebase errors 1\n",
    "#expId = 2023110700519 # Timebase errors 2\n",
    "#expId = 2023122200404 # 5 second crzy mount\n",
    "\n",
    "dataId = {'detector':0, 'exposure':expId}\n",
    "\n",
    "butler = new_butler\n",
    "\n",
    "expRecord = butlerUtils.getExpRecordFromDataId(butler, dataId)\n",
    "dayString = dayObsIntToString(expRecord.day_obs)\n",
    "seqNumString = str(expRecord.seq_num)\n",
    "dataIdString = f\"{dayString} - seqNum {seqNumString}\"\n",
    "\n",
    "\n",
    "tStart = expRecord.timespan.begin.tai.to_value(\"isot\")\n",
    "tEnd = expRecord.timespan.end.tai.to_value(\"isot\")\n",
    "elevation = 90.0 - expRecord.zenith_angle\n",
    "\n",
    "# TODO: DM-33859 remove this once it can be got from the expRecord\n",
    "md = butler.get('raw.metadata', dataId, detector=0)\n",
    "obsInfo = ObservationInfo(md)\n",
    "azimuth = obsInfo.altaz_begin.az.value\n",
    "# Time base in the EFD is still a big mess.  Although these times are in\n",
    "# UTC, it is necessary to tell the code they are in TAI. Then it is\n",
    "# necessary to tell the merge_packed_time_series to use UTC.\n",
    "# After doing all of this, there is still a 2 second offset,\n",
    "# which is discussed in JIRA ticket DM-29243, but not understood.\n",
    "\n",
    "t_start = Time(tStart, scale='tai')\n",
    "t_end = Time(tEnd, scale='tai')\n",
    "\n",
    "mount_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_AzEl_Encoders\", t_start, t_end)\n",
    "nasmyth_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_Nasmyth_Encoders\", t_start, t_end)\n",
    "torques = _getEfdData(client, \"lsst.sal.ATMCS.measuredTorque\", t_start, t_end)\n",
    "\n",
    "az = mpts(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "el = mpts(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "rot = mpts(nasmyth_position, 'nasmyth2CalculatedAngle', stride=1)\n",
    "az_torque_1 = mpts(torques, 'azimuthMotor1Torque', stride=1)\n",
    "az_torque_2 = mpts(torques, 'azimuthMotor2Torque', stride=1)\n",
    "el_torque = mpts(torques, 'elevationMotorTorque', stride=1)\n",
    "rot_torque = mpts(torques, 'nasmyth2MotorTorque', stride=1)\n",
    "\n",
    "# Calculate the tracking errors\n",
    "az_vals = np.array(az.values[:, 0])\n",
    "el_vals = np.array(el.values[:, 0])\n",
    "rot_vals = np.array(rot.values[:, 0])\n",
    "times = np.array(az.values[:, 1])\n",
    "# The fits are much better if the time variable\n",
    "# is centered in the interval\n",
    "fit_times = times - times[int(len(az.values[:, 1]) / 2)]\n",
    "\n",
    "# Fit with a polynomial\n",
    "az_fit = np.polyfit(fit_times, az_vals, 4)\n",
    "el_fit = np.polyfit(fit_times, el_vals, 4)\n",
    "rot_fit = np.polyfit(fit_times, rot_vals, 2)\n",
    "az_model = np.polyval(az_fit, fit_times)\n",
    "el_model = np.polyval(el_fit, fit_times)\n",
    "rot_model = np.polyval(rot_fit, fit_times)\n",
    "\n",
    "# Errors in arcseconds\n",
    "az_error = (az_vals - az_model) * 3600\n",
    "el_error = (el_vals - el_model) * 3600\n",
    "rot_error = (rot_vals - rot_model) * 3600\n",
    "\n",
    "# Calculate RMS\n",
    "az_rms = np.sqrt(np.mean(az_error * az_error))\n",
    "el_rms = np.sqrt(np.mean(el_error * el_error))\n",
    "rot_rms = np.sqrt(np.mean(rot_error * rot_error))\n",
    "\n",
    "# Calculate Image impact RMS\n",
    "image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)\n",
    "image_el_rms = el_rms\n",
    "image_rot_rms = rot_rms * AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC * np.pi / 180.0 / 3600.0\n",
    "tot_rms = np.sqrt(image_az_rms**2 + image_el_rms**2 + image_rot_rms**2)\n",
    "\n",
    "# Check the timebase errors\n",
    "cRIO_ts = mount_position[\"cRIO_timestamp\"]\n",
    "timestamps = cRIO_ts.values\n",
    "deltaTs = []\n",
    "for n in range(1, len(timestamps)):\n",
    "    deltaTs.append(timestamps[n] - timestamps[n-1])\n",
    "print(\"Mean deltaT\", np.mean(deltaTs), \"Max deltaT\", np.max(deltaTs)) \n",
    "# Calculate the FFT peaks\n",
    "fft_peaks = []\n",
    "fig, axs = plt.subplots(1,2)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "numKnots = 18\n",
    "knotList = []\n",
    "names = [\"Azimuth\", \"Elevation\"]\n",
    "for i, error in enumerate([az_error, el_error]):\n",
    "    # Number of samples in normalized_tone\n",
    "    N = len(error)\n",
    "    SAMPLE_RATE = 100 # Samples/sec\n",
    "    yf = fft(error)\n",
    "    xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "    yf = np.abs(fft(error))\n",
    "    count = 0\n",
    "    for n in range(len(xf)):\n",
    "        if xf[n] < 5.0:\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    print(count)\n",
    "    xf = xf[0:count]\n",
    "    yf = yf[0:count]\n",
    "    \"\"\"            \n",
    "    numKnots = 40\n",
    "    knots = np.linspace(xf[1], xf[-2], numKnots)\n",
    "    spline = LSQUnivariateSpline(xf, yf, knots)\n",
    "    #knots = spline.get_knots()\n",
    "    values = spline(knots)\n",
    "\n",
    "    \"\"\"\n",
    "    numKnots = 20\n",
    "    s, knots = findSpline(xf, yf, numKnots=numKnots)\n",
    "    spline = UnivariateSpline(xf, yf, s=s)\n",
    "    knots = spline.get_knots()\n",
    "    values = spline(knots)\n",
    "    #print(len(knots), len(values))\n",
    "    \n",
    "    if len(knots) < numKnots:\n",
    "        numToAdd = int(numKnots - len(knots))\n",
    "        lenKnots = knots[-1] - knots[0]\n",
    "        for n in range(numToAdd):\n",
    "            newKnot = knots[-1] + 0.01 * (n+1)\n",
    "            newValue = values[-1]\n",
    "            knots = np.append(knots, newKnot)\n",
    "            values = np.append(values, newValue)\n",
    "    if len(knots) > numKnots:\n",
    "        knots = np.delete(knots, [-2])\n",
    "        values = np.delete(values, [-2])\n",
    "    axs[i].set_title(names[i])\n",
    "    axs[i].plot(xf, yf, color='blue')\n",
    "    axs[i].plot(xf, spline(xf), ls='--', color='red')\n",
    "    axs[i].scatter(knots, values, marker='x', color='red')\n",
    "    axs[i].set_xlabel(\"Frequency(Hz)\")\n",
    "    axs[i].set_ylabel(\"Amplitude\")\n",
    "    print(i, len(knots))\n",
    "    for n in range(numKnots):\n",
    "        knotList.append(knots[n])\n",
    "        knotList.append(values[n])\n",
    "print(len(knotList))\n",
    "#print(knotList)\n",
    "plt.savefig(f\"/home/c/cslage/u/AuxTel/mount_classifier/Spline_Knots_{expId}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855e5d0-4369-41bb-a496-4b6379d3cdb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T11:59:45.209160Z",
     "iopub.status.busy": "2023-12-30T11:59:45.208594Z",
     "iopub.status.idle": "2023-12-30T11:59:45.211543Z",
     "shell.execute_reply": "2023-12-30T11:59:45.211126Z",
     "shell.execute_reply.started": "2023-12-30T11:59:45.209144Z"
    }
   },
   "outputs": [],
   "source": [
    "causes = ['OSC', 'WIN', 'CRA', 'TIM', 'SHU', 'GOOD', 'UNSURE']\n",
    "fullCauses = ['UNSURE', 'OSC', 'WIN', 'CRA', 'TIM', 'SHU', 'GOOD'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba014fd1-226c-43bd-b457-f3c836ca1147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T11:59:45.957808Z",
     "iopub.status.busy": "2023-12-30T11:59:45.957239Z",
     "iopub.status.idle": "2023-12-30T11:59:45.961486Z",
     "shell.execute_reply": "2023-12-30T11:59:45.961056Z",
     "shell.execute_reply.started": "2023-12-30T11:59:45.957793Z"
    }
   },
   "outputs": [],
   "source": [
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_Errors_Classified_Dict_29Dec23.pkl', 'rb')\n",
    "Mount_Errors_Classified_Dict = pkl.load(infile)\n",
    "infile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70162854-c18e-49b3-b650-062d1ea3f12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T12:09:28.823070Z",
     "iopub.status.busy": "2023-12-30T12:09:28.822689Z",
     "iopub.status.idle": "2023-12-30T12:09:28.825511Z",
     "shell.execute_reply": "2023-12-30T12:09:28.825169Z",
     "shell.execute_reply.started": "2023-12-30T12:09:28.823057Z"
    }
   },
   "outputs": [],
   "source": [
    "for cause in fullCauses:\n",
    "    print(cause, Mount_Errors_Classified_Dict[20231204][cause])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54319fd2-658b-4c20-83fe-6c1b3767fb9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T12:08:00.343774Z",
     "iopub.status.busy": "2023-12-30T12:08:00.343384Z",
     "iopub.status.idle": "2023-12-30T12:08:00.550843Z",
     "shell.execute_reply": "2023-12-30T12:08:00.550437Z",
     "shell.execute_reply.started": "2023-12-30T12:08:00.343760Z"
    }
   },
   "outputs": [],
   "source": [
    "fullCauses = ['UNSURE', 'OSC', 'WIN', 'CRA', 'TIM', 'SHU', 'GOOD'] \n",
    "\n",
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_Errors_Classified_Dict_29Dec23.pkl', 'rb')\n",
    "Mount_Errors_Classified_Dict = pkl.load(infile)\n",
    "infile.close()\n",
    "\n",
    "plotColors = ['gray', 'red', 'blue', 'violet', 'yellow', 'cyan', 'green']\n",
    "dates = Mount_Errors_Classified_Dict.keys()\n",
    "plotDates = []\n",
    "plotList = []\n",
    "xticks = []\n",
    "\n",
    "skipDates = 2\n",
    "# Somehow some empty lists got in\n",
    "# This cleans them out\n",
    "badDates = []\n",
    "for date in dates:\n",
    "    if len(Mount_Errors_Classified_Dict[date]['GOOD']) < 5:\n",
    "        badDates.append(date)\n",
    "for date in badDates:\n",
    "    del Mount_Errors_Classified_Dict[date]\n",
    "        \n",
    "dates = Mount_Errors_Classified_Dict.keys()\n",
    "data = np.zeros([len(dates), len(fullCauses)])\n",
    "for i, date in enumerate(dates):\n",
    "    for j, cause in enumerate(fullCauses):\n",
    "        data[i,j] = len(Mount_Errors_Classified_Dict[date][cause])\n",
    "for i, date in enumerate(dates):\n",
    "    sum = data[i,:].sum()\n",
    "    if i % skipDates == 0:\n",
    "        xticks.append(str(date))\n",
    "    else:\n",
    "        xticks.append(\"\")\n",
    "    plotDates.append(str(date))\n",
    "    for j, cause in enumerate(fullCauses):\n",
    "        data[i,j] /= sum\n",
    "        data[i,j] *= 100.0\n",
    "\n",
    "for j, cause in enumerate(fullCauses):\n",
    "    plotList.append(data[:,j])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.set_title(\"AuxTel types of mount fails - 2023\", fontsize=18)\n",
    "ax.stackplot(plotDates, plotList, labels=fullCauses, colors=plotColors)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_ylabel(\"Percent\")\n",
    "ax.set_xticks(ticks=plotDates,labels=xticks, rotation=90)\n",
    "plt.savefig('/home/c/cslage/u/AuxTel/mount_classifier/Mount_Fails_Classified_2023.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25ff7d-a9d4-468e-9f7d-1d44204bdddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-02T14:26:58.969074Z",
     "iopub.status.busy": "2024-01-02T14:26:58.968770Z",
     "iopub.status.idle": "2024-01-02T14:27:04.327839Z",
     "shell.execute_reply": "2024-01-02T14:27:04.327358Z",
     "shell.execute_reply.started": "2024-01-02T14:26:58.969059Z"
    }
   },
   "outputs": [],
   "source": [
    "infile = open('/home/c/cslage/u/AuxTel/mount_classifier/Mount_Errors_Classified_Dict_29Dec23.pkl', 'rb')\n",
    "Mount_Errors_Classified_Dict = pkl.load(infile)\n",
    "infile.close()\n",
    "dates = Mount_Errors_Classified_Dict.keys()\n",
    "\n",
    "client = EfdClient('idf_efd') # Before 20231211  \n",
    "fullCauses = ['UNSURE', 'OSC', 'WIN', 'CRA', 'TIM', 'SHU', 'GOOD'] \n",
    "from lsst.summit.utils.efdUtils import calcNextDay\n",
    "windSpeeds = []\n",
    "windFails = []\n",
    "for date in dates:\n",
    "    try:\n",
    "        dayObs = int(date)\n",
    "        dateTime = datetime.strptime(str(dayObs), \"%Y%m%d\")\n",
    "        dayObsDate = f\"{dateTime.year}-{dateTime.month}-{dateTime.day}\"\n",
    "        nextDayObs = calcNextDay(dayObs)\n",
    "        dateTime = datetime.strptime(str(nextDayObs), \"%Y%m%d\")\n",
    "        nextDayObsDate = f\"{dateTime.year}-{dateTime.month}-{dateTime.day}\"\n",
    "        start = Time(f\"{dayObsDate} 23:00:00Z\", scale='utc')\n",
    "        end = Time(f\"{nextDayObsDate} 08:00:00Z\", scale='utc')\n",
    "        maxSpeed = await client.select_time_series('lsst.sal.ESS.airFlow', \\\n",
    "                                                ['maxSpeed'],  start, end, index=301)\n",
    "        windSpeed = np.median(maxSpeed['maxSpeed'].values)\n",
    "        total = 0\n",
    "        for cause in fullCauses:\n",
    "            total += len(Mount_Errors_Classified_Dict[date][cause])\n",
    "            if cause == 'WIN':\n",
    "                windFail = len(Mount_Errors_Classified_Dict[date][cause])\n",
    "        windFail = windFail / total * 100.0\n",
    "        windSpeeds.append(windSpeed)\n",
    "        windFails.append(windFail)\n",
    "    except:\n",
    "        continue\n",
    "print(len(windSpeeds), len(windFails))\n",
    "plt.scatter(windSpeeds, windFails)\n",
    "plt.title(\"Mount fails due to wind jitter vs median wind speed\", fontsize=16)\n",
    "plt.ylabel(\"Percent fails due to wind jitter\")\n",
    "plt.xlabel(\"Median wind speed (m/s)\")\n",
    "plt.savefig('/home/c/cslage/u/AuxTel/mount_classifier/Wind_Fails_vs_Wind_Speed_2023.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3548d-e6eb-4062-8383-448c95231893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae79395-d3db-4f7f-988a-825a1a8a5266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
