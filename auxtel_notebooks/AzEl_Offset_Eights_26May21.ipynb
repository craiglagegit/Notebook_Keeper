{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AuxTel AzEl offsets - 26-May-21\n",
    "\n",
    "In this notebook, investigate az-el offsets from 25-May-21\\\n",
    "This is going to analyze a figure 8 of exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, os, asyncio, glob\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import astropy.io.fits as pf\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord, AltAz, ICRS, EarthLocation, Angle, FK5\n",
    "import astropy.units as u\n",
    "\n",
    "from lsst.daf.butler import Butler as gen3Butler\n",
    "from lsst.daf.persistence import Butler as gen2Butler\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.pipe.tasks.characterizeImage import CharacterizeImageTask, CharacterizeImageConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get EFD client\n",
    "#client = EfdClient('ldf_stable_efd')\n",
    "client = EfdClient('summit_efd')\n",
    "\n",
    "def merge_packed_time_series(packed_dataframe, base_field, stride=1, \n",
    "                             ref_timestamp_col=\"cRIO_timestamp\", internal_time_scale=\"tai\"):\n",
    "    \"\"\"Select fields that are time samples and unpack them into a dataframe.\n",
    "            Parameters\n",
    "            ----------\n",
    "            packedDF : `pandas.DataFrame`\n",
    "                packed data frame containing the desired data\n",
    "            base_field :  `str`\n",
    "                Base field name that will be expanded to query all\n",
    "                vector entries.\n",
    "            stride : `int`, optional\n",
    "                Only use every stride value when unpacking.  Must be a factor\n",
    "                of the number of packed values.\n",
    "                (1 by default)\n",
    "            ref_timestamp_col : `str`, optional\n",
    "                Name of the field name to use to assign timestamps to unpacked\n",
    "                vector fields (default is 'cRIO_timestamp').\n",
    "            internal_time_scale : `str`, optional\n",
    "                Time scale to use when converting times to internal formats\n",
    "                ('tai' by default). Equivalent to EfdClient.internal_scale\n",
    "        Returns\n",
    "            -------\n",
    "            result : `pandas.DataFrame`\n",
    "                A `pandas.DataFrame` containing the results of the query.\n",
    "            \"\"\"\n",
    "    \n",
    "    packed_fields = [k for k in packed_dataframe.keys() if k.startswith(base_field)]\n",
    "    packed_fields = sorted(packed_fields, key=lambda k: int(k[len(base_field):]))  # sort by pack ID\n",
    "    npack = len(packed_fields)\n",
    "    if npack%stride != 0:\n",
    "        raise RuntimeError(f\"Stride must be a factor of the number of packed fields: {stride} v. {npack}\")\n",
    "    packed_len = len(packed_dataframe)\n",
    "    n_used = npack//stride   # number of raw fields being used\n",
    "    output = np.empty(n_used*packed_len)\n",
    "    times = np.empty_like(output, dtype=packed_dataframe[ref_timestamp_col][0])\n",
    "    \n",
    "    if packed_len == 1:\n",
    "        dt = 0\n",
    "    else:\n",
    "        dt = (packed_dataframe[ref_timestamp_col][1] - packed_dataframe[ref_timestamp_col][0])/npack\n",
    "    for i in range(0, npack, stride):\n",
    "        i0 = i//stride\n",
    "        output[i0::n_used] = packed_dataframe[f\"{base_field}{i}\"]\n",
    "        times[i0::n_used] = packed_dataframe[ref_timestamp_col] + i*dt\n",
    "     \n",
    "    timestamps = Time(times, format='unix', scale=internal_time_scale).datetime64\n",
    "    return pd.DataFrame({base_field:output, \"times\":times}, index=timestamps)\n",
    "\n",
    "# This makes the plots more readable\n",
    "def colorbar(mappable):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen3 butler\n",
    "dayObs = 20210525\n",
    "REPO_DIR = '/repo/main'\n",
    "butler_g3 = gen3Butler(REPO_DIR, collections=\"LATISS/raw/all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get all of the tracking data\n",
    "\n",
    "firstExpId = 2021052500153\n",
    "lastExpId = 2021052500161\n",
    "charVisits = {}\n",
    "plotCounter = 1\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "plt.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "for expId in range(firstExpId, lastExpId+1):\n",
    "    charVisit = {}\n",
    "    if expId == firstExpId:\n",
    "        expId1 = expId\n",
    "        mData1 = butler_g3.get('raw.metadata', detector=0, exposure=expId1)\n",
    "        exp1Start = Time(mData1['DATE-BEG'],scale='tai') - TimeDelta(4.0, format = 'sec')\n",
    "    else:\n",
    "        expId1 = expId-1\n",
    "        mData1 = butler_g3.get('raw.metadata', detector=0, exposure=expId1)\n",
    "        exp1Start = Time(mData1['DATE-BEG'],scale='tai')\n",
    "    exp1End = Time(mData1['DATE-END'],scale='tai')\n",
    "    expId2 = expId\n",
    "    mData2 = butler_g3.get('raw.metadata', detector=0, exposure=expId2)\n",
    "    exp2Start = Time(mData2['DATE-BEG'],scale='tai')\n",
    "    exp2End = Time(mData2['DATE-END'],scale='tai')\n",
    "    charVisit['mData'] = mData2\n",
    "    # These are for finding the timestamps of the offset event\n",
    "    offsets = await client.select_time_series(\"lsst.sal.ATPtg.command_offsetAzEl\", ['*'],\n",
    "                                          exp1Start, exp2End)\n",
    "    if len(offsets) > 0:\n",
    "        offsetTime = Time(offsets.index[0],scale='tai')\n",
    "        commandedAzShift = offsets.values[0][0] / np.cos(mData1['ELSTART'] * np.pi / 180.0)\n",
    "        commandedElShift = offsets.values[0][1]\n",
    "        # Now get the mount data\n",
    "        mount_position = await client.select_time_series(\"lsst.sal.ATMCS.mount_AzEl_Encoders\", ['*'],\n",
    "                                              exp1Start, exp2End)\n",
    "        az = merge_packed_time_series(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "        el = merge_packed_time_series(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "\n",
    "        # Calculate the tracking shift\n",
    "        az_vals = np.array(az.values.tolist())[:,0]\n",
    "        el_vals = np.array(el.values.tolist())[:,0]\n",
    "        times = np.array(az.values.tolist())[:,1] - 35.84 ## WHY??\n",
    "        zeroTime = times[0]\n",
    "        times -= zeroTime\n",
    "        #shiftIndex = np.where(times>offsetTime.tai.unix-zeroTime)[0][0]\n",
    "        valsPerSecond = 100\n",
    "        n1 = np.where(times>exp1Start.tai.unix-zeroTime)[0][0] # Start of first exposure\n",
    "        n2 = np.where(times>offsetTime.tai.unix-zeroTime)[0][0] # Time of commanded offset\n",
    "        n3 = np.where(times>exp2Start.tai.unix-zeroTime)[0][0] # Start of second exposure\n",
    "        n4 = len(times)\n",
    "\n",
    "        # Fit the tracking before the offset with a quadratic\n",
    "        az_vals_fit = az_vals[n1:n2]\n",
    "        el_vals_fit = el_vals[n1:n2]\n",
    "        times_fit = times[n1:n2]\n",
    "        az_fit = np.polyfit(times_fit, az_vals_fit, 1)\n",
    "        el_fit = np.polyfit(times_fit, el_vals_fit, 1)\n",
    "        print(expId, \"az_fit\", az_fit, \"el_fit\", el_fit)\n",
    "        #az_model = az_fit[0] * times * times + az_fit[1] * times + az_fit[2]\n",
    "        #el_model = el_fit[0] * times * times + el_fit[1] * times + el_fit[2]\n",
    "        az_model = az_fit[0] * times + az_fit[1]\n",
    "        el_model = el_fit[0] * times  + el_fit[1]\n",
    "\n",
    "        # Apply this model and calculate the departure from the model after the shift\n",
    "        az_error = (az_vals - az_model) * 3600\n",
    "        el_error = (el_vals - el_model) * 3600\n",
    "\n",
    "        az_shift = np.mean(az_error[n3:n4])\n",
    "        el_shift = np.mean(el_error[n3:n4])\n",
    "        if abs(el_shift) > abs(az_shift):\n",
    "            ymax = 10.0 * int(el_shift / 10.0) * 1.2\n",
    "        else:\n",
    "            ymax = 10.0 * int(az_shift / 10.0) * 1.2\n",
    "        ymin = -ymax / 5.0\n",
    "        ymid = ymax * 0.6\n",
    "        plt.subplot(3, 3, plotCounter)\n",
    "        plt.title(f\"Offset - {dayObs} - {expId}\", fontsize = 12)\n",
    "        plt.plot([exp1Start.tai.unix-zeroTime, exp1End.tai.unix-zeroTime], [ymin*0.5,ymin*0.5], color='red', lw=2.0, label=f\"exp:{expId1}\")\n",
    "        plt.plot([exp2Start.tai.unix-zeroTime, exp2End.tai.unix-zeroTime], [ymin*0.5,ymin*0.5], color='red', lw=2.0, label=f\"exp:{expId2}\")\n",
    "        plt.plot([offsetTime.tai.unix-zeroTime,offsetTime.tai.unix-zeroTime], [ymin*0.5, ymin*0.1], color='blue', lw=2.0, label=\"Commanded Offset\")\n",
    "        plt.plot(times, az_error, color='green', label=\"Az shift\")\n",
    "        plt.text(times[0], ymid*0.8, f\"Measured az shift = \\n{az_shift:.2f} arcsec\", fontsize=9)\n",
    "        plt.text(times[0], ymid*0.6, f\"Commanded az shift = \\n{commandedAzShift:.1f} arcsec\", fontsize=9)\n",
    "        plt.plot(times, el_error, color='black', label=\"El shift\")\n",
    "        plt.text(times[0], ymid*0.4, f\"Measured el shift = \\n{el_shift:.2f} arcsec\", fontsize=9)\n",
    "        plt.text(times[0], ymid*0.2, f\"Commanded el shift = \\n{commandedElShift:.1f} arcsec\", fontsize=9)\n",
    "        plt.ylabel(\"Arcsec\")\n",
    "        plt.xlabel(\"Time (Unix - seconds)\")\n",
    "        plt.legend(loc='upper left', fontsize=8)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plotCounter += 1\n",
    "        \n",
    "    else:\n",
    "        commandedAzShift = 0.0\n",
    "        commandedElShift = 0.0\n",
    "        az_shift = 0.0\n",
    "        el_shift = 0.0\n",
    "    charVisit['commandedAzShift'] = commandedAzShift\n",
    "    charVisit['commandedElShift'] = commandedElShift\n",
    "    charVisit['az_shift'] = az_shift\n",
    "    charVisit['el_shift'] = el_shift\n",
    "    charVisits[f\"{expId}\"] = charVisit\n",
    "\n",
    "plt.savefig(f\"/project/cslage/AuxTel/offsets/Offsets_{expId1}_{expId2}_25May21.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw quickLook data.  Only Gen2 works for now\n",
    "REPO_DIR = '/project/shared/auxTel/rerun/quickLook'\n",
    "gen2_butler = gen2Butler(REPO_DIR)\n",
    "dayObs = '2021-05-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the image data\n",
    "charConfig = CharacterizeImageConfig()\n",
    "charConfig.doMeasurePsf = False#True\n",
    "charConfig.doApCorr = False\n",
    "charConfig.doDeblend = False\n",
    "charConfig.repair.doCosmicRay = True\n",
    "charConfig.repair.doInterpolate = True   \n",
    "charConfig.detection.minPixels = 500\n",
    "charTask = CharacterizeImageTask(config=charConfig)\n",
    "\n",
    "for expId in range(firstExpId, lastExpId+1):\n",
    "    charVisit = charVisits[f\"{expId}\"]\n",
    "    exp = gen2_butler.get('quickLookExp', detector=0, expId=expId)\n",
    "    charResult = charTask.run(exp)\n",
    "    sourceCatalog = charResult.sourceCat\n",
    "    maxFlux = np.nanmax(sourceCatalog['base_CircularApertureFlux_3_0_instFlux'])\n",
    "    selectBrightestSource = sourceCatalog['base_CircularApertureFlux_3_0_instFlux'] > maxFlux * 0.99\n",
    "    brightestSource = sourceCatalog.subset(selectBrightestSource)\n",
    "    brightestCentroid = (brightestSource['base_SdssCentroid_x'][0], \\\n",
    "                         brightestSource['base_SdssCentroid_y'][0])\n",
    "    brightCatalog = sourceCatalog.subset(sourceCatalog['base_CircularApertureFlux_3_0_instFlux'] > maxFlux * 0.0001)\n",
    "    print(f\"expId:{expId}. Found {len(sourceCatalog)} sources, {len(brightCatalog)} bright sources\")\n",
    "    print(f\"Brightest centroid at {brightestCentroid}\")\n",
    "    charVisit['exp'] = exp\n",
    "    charVisit['brightestCentroid'] = brightestCentroid\n",
    "    charVisit['brightCatalog'] = brightCatalog\n",
    "    charVisits[f\"{expId}\"] = charVisit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mData = charVisits[str(firstExpId)]['mData']\n",
    "pointingCoords = SkyCoord(ra=mData['RASTART']*u.degree, dec=mData['DECSTART']*u.degree)\n",
    "pointingAltaz = AltAz(az=mData['AZSTART']*u.degree, alt=mData['ELSTART']*u.degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cerro Pachon location and observation time\n",
    "mData = charVisits[str(firstExpId)]['mData']\n",
    "location = EarthLocation.from_geodetic(lon=mData['OBS-LONG']*u.deg,\n",
    "                                       lat=mData['OBS-LAT']*u.deg,\n",
    "                                       height=mData['OBS-ELEV']*u.m)\n",
    "\n",
    "utcoffset = -4*u.hour  \n",
    "time = Time(mData['DATE-BEG']) + utcoffset\n",
    "time.format = 'iso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinTheta =  np.cos(location.lat.rad) / np.cos(pointingCoords.dec.rad) * np.sin(pointingAltaz.az.rad)\n",
    "theta = Angle(np.arcsin(sinTheta)*180.0 / np.pi * u.deg)\n",
    "print(theta.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "Ncenter = (3000,3000)\n",
    "NcenterAzEl = (1000,3000)\n",
    "Nlength = 500.0\n",
    "Nlabel = 600.0\n",
    "yShift = 150.0\n",
    "shiftCounter = 0\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "for expId in range(firstExpId, lastExpId+1):\n",
    "    seqNo = expId - firstExpId\n",
    "    charVisit = charVisits[f\"{expId}\"]\n",
    "    plt.subplot(1,1,1)\n",
    "    plt.title(f\"Figure Eight - {firstExpId} - {lastExpId}\",fontsize=18)\n",
    "    plt.scatter([charVisit['brightestCentroid'][0]],[charVisit['brightestCentroid'][1]] \\\n",
    "                ,color='yellow', marker='+', s=400)\n",
    "    if seqNo == 0:\n",
    "        arr = charVisit['exp'].image.array\n",
    "        arr = np.clip(arr, 1, 100000) # This image has some negative values, and this removes them\n",
    "        img = plt.imshow(arr, norm=LogNorm(vmin=1, vmax=1000),  interpolation='Nearest', cmap='gray')\n",
    "\n",
    "        cat = charVisit['brightCatalog']\n",
    "        rotpa = Angle(-113.57*u.deg)#  Header wrong for these images  Angle(charVisit['mData']['ROTPA']*u.deg)\n",
    "        plt.arrow(Ncenter[0],Ncenter[1], -Nlength*np.sin(rotpa), Nlength*np.cos(rotpa),\\\n",
    "            color='green', width = 20)\n",
    "        plt.text(Ncenter[0]-Nlabel*np.sin(rotpa),Ncenter[1]+Nlabel*np.cos(rotpa), 'N', \\\n",
    "            color='green', fontsize=12, weight='bold')\n",
    "        plt.arrow(Ncenter[0],Ncenter[1], Nlength*np.cos(rotpa), Nlength*np.sin(rotpa),\\\n",
    "            color='green', width = 20)\n",
    "        plt.text(Ncenter[0]+Nlabel*np.cos(rotpa),Ncenter[1]+Nlabel*np.sin(rotpa), 'E', \\\n",
    "            color='green', fontsize=12, weight='bold')\n",
    "\n",
    "        rotAzEl = rotpa - theta\n",
    "        print(rotpa.deg, rotAzEl.deg)\n",
    "        plt.arrow(NcenterAzEl[0],NcenterAzEl[1], -Nlength*np.sin(rotAzEl), Nlength*np.cos(rotAzEl),\\\n",
    "            color='cyan', width = 20)\n",
    "        plt.text(NcenterAzEl[0]-Nlabel*np.sin(rotAzEl),NcenterAzEl[1]+Nlabel*np.cos(rotAzEl), 'EL', \\\n",
    "            color='cyan', fontsize=12, weight='bold')\n",
    "        plt.arrow(NcenterAzEl[0],NcenterAzEl[1], Nlength*np.cos(rotAzEl), Nlength*np.sin(rotAzEl),\\\n",
    "            color='cyan', width = 20)\n",
    "        plt.text(NcenterAzEl[0]+Nlabel*np.cos(rotAzEl),NcenterAzEl[1]+Nlabel*np.sin(rotAzEl), 'AZ', \\\n",
    "            color='cyan', fontsize=12, weight='bold')\n",
    "\n",
    "    if seqNo in [0,4,8]:\n",
    "        plt.text((charVisit['brightestCentroid'][0]+100), \\\n",
    "                 (charVisit['brightestCentroid'][1] + shiftCounter*yShift), \\\n",
    "                 f\"{seqNo} az={charVisit['commandedAzShift']:.1f} el={charVisit['commandedElShift']:.1f}\", \\\n",
    "                 color='yellow', fontsize=12, weight='bold')\n",
    "        \n",
    "        shiftCounter += 1\n",
    "    else:\n",
    "        plt.text((charVisit['brightestCentroid'][0]+100), \\\n",
    "                 (charVisit['brightestCentroid'][1]), \\\n",
    "                 f\"{seqNo} az={charVisit['commandedAzShift']:.1f}\\n       el={charVisit['commandedElShift']:.1f}\", \\\n",
    "                 color='yellow', fontsize=12, weight='bold')\n",
    "    #plt.xlim(0,4000)\n",
    "    #plt.ylim(4000,0)\n",
    "plt.tight_layout(h_pad=1)\n",
    "#plt.savefig(f\"/project/cslage/AuxTel/offsets/Offsets_Figure_Eight_{firstExpId}_{lastExpId}_25May21.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
