{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cc3a14-f377-44f4-ab4c-97c9c3047697",
   "metadata": {},
   "source": [
    "# Fourier transform of mount errors\n",
    "\n",
    "Craig Lage - 27-Nov-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148b369-8943-4861-a51e-9cbeea70feb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:59:11.667877Z",
     "iopub.status.busy": "2023-11-30T13:59:11.667438Z",
     "iopub.status.idle": "2023-11-30T13:59:11.673865Z",
     "shell.execute_reply": "2023-11-30T13:59:11.673099Z",
     "shell.execute_reply.started": "2023-11-30T13:59:11.667840Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import sys, time, os, asyncio\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.daf.butler import Butler\n",
    "from lsst.ts.observing.utilities.decorated_logger import DecoratedLogger\n",
    "\n",
    "import lsst.summit.utils.butlerUtils as butlerUtils\n",
    "from lsst.summit.utils.utils import dayObsIntToString\n",
    "from astro_metadata_translator import ObservationInfo\n",
    "from lsst_efd_client import merge_packed_time_series as mpts\n",
    "\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b3867-c6db-43d3-8248-ecfcd41d3fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:56:45.141175Z",
     "iopub.status.busy": "2023-11-30T13:56:45.140734Z",
     "iopub.status.idle": "2023-11-30T13:56:47.105014Z",
     "shell.execute_reply": "2023-11-30T13:56:47.104483Z",
     "shell.execute_reply.started": "2023-11-30T13:56:45.141150Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = EfdClient('summit_efd')\n",
    "butler = Butler('/repo/LATISS', collections=[\"LATISS/raw/all\", \"LATISS/calib\"])\n",
    "logger = DecoratedLogger.get_decorated_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adebfb-5a29-4f8a-9336-bc9c19bef499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T13:57:23.031360Z",
     "iopub.status.busy": "2023-11-30T13:57:23.030728Z",
     "iopub.status.idle": "2023-11-30T13:57:23.036947Z",
     "shell.execute_reply": "2023-11-30T13:57:23.036206Z",
     "shell.execute_reply.started": "2023-11-30T13:57:23.031329Z"
    }
   },
   "outputs": [],
   "source": [
    "NON_TRACKING_IMAGE_TYPES = ['BIAS',\n",
    "                            'FLAT',\n",
    "                            ]\n",
    "\n",
    "AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC = 280.0\n",
    "MOUNT_IMAGE_WARNING_LEVEL = .25  # this determines the colouring of the cells in the table, yellow for this\n",
    "MOUNT_IMAGE_BAD_LEVEL = .4\n",
    "\n",
    "\n",
    "def _getEfdData(client, dataSeries, startTime, endTime):\n",
    "    \"\"\"A synchronous warpper for geting the data from the EFD.\n",
    "\n",
    "    This exists so that the top level functions don't all have to be async def.\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(client.select_time_series(dataSeries, ['*'], startTime.utc, endTime.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29298ea-cb53-4a53-accb-0d59956745c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T22:31:33.481562Z",
     "iopub.status.busy": "2023-11-30T22:31:33.481217Z",
     "iopub.status.idle": "2023-11-30T22:31:33.498974Z",
     "shell.execute_reply": "2023-11-30T22:31:33.498417Z",
     "shell.execute_reply.started": "2023-11-30T22:31:33.481535Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculateFFTPeaks(dataId, butler, client):\n",
    "    \"\"\"Queries EFD for a given exposure and calculates the RMS errors in the\n",
    "    axes during the exposure, optionally plotting and saving the data.\n",
    "\n",
    "    Returns ``False`` if the analysis fails or is skipped e.g. due to the\n",
    "    expTime being too short.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataId : `dict` or `lsst.daf.butler.DataCoordinate`\n",
    "        The dataId for which to plot the mount torques.\n",
    "    butler : `lsst.daf.butler.Butler`\n",
    "        The butler to use to retrieve the image metadata.\n",
    "    client : `lsst_efd_client.Client`\n",
    "        The EFD client to retrieve the mount torques.\n",
    "    figure : `matplotlib.figure.Figure`\n",
    "        A matplotlib figure to re-use. Necessary to pass this in to prevent an\n",
    "        ever-growing figure count and the ensuing memory leak.\n",
    "    saveFilename : `str`\n",
    "        Full path and filename to save the plot to.\n",
    "    logger : `logging.Logger`\n",
    "        The logger.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    axisErrors : `dict` or `False`\n",
    "        The RMS errors in the three axes and their image contributions:\n",
    "        ``az_rms`` - The RMS azimuth error.\n",
    "        ``el_rms`` - The RMS elevation error.\n",
    "        ``rot_rms`` - The RMS rotator error.\n",
    "        ``image_az_rms`` - The RMS azimuth error for the image.\n",
    "        ``image_el_rms`` - The RMS elevation error for the image.\n",
    "        ``image_rot_rms`` - The RMS rotator error for the image.\n",
    "    \"\"\"\n",
    "    # lsst-efd-client is not a required import at the top here, but is\n",
    "    # implicitly required as a client is passed into this function so is not\n",
    "    # rechecked here.\n",
    "\n",
    "    expRecord = butlerUtils.getExpRecordFromDataId(butler, dataId)\n",
    "    dayString = dayObsIntToString(expRecord.day_obs)\n",
    "    seqNumString = str(expRecord.seq_num)\n",
    "    dataIdString = f\"{dayString} - seqNum {seqNumString}\"\n",
    "\n",
    "    imgType = expRecord.observation_type.upper()\n",
    "    if imgType in NON_TRACKING_IMAGE_TYPES:\n",
    "        return False\n",
    "\n",
    "    exptime = expRecord.exposure_time\n",
    "    if exptime < 1.99:\n",
    "        return False\n",
    "\n",
    "    tStart = expRecord.timespan.begin.tai.to_value(\"isot\")\n",
    "    tEnd = expRecord.timespan.end.tai.to_value(\"isot\")\n",
    "    elevation = 90 - expRecord.zenith_angle\n",
    "\n",
    "    # TODO: DM-33859 remove this once it can be got from the expRecord\n",
    "    md = butler.get('raw.metadata', dataId, detector=0)\n",
    "    obsInfo = ObservationInfo(md)\n",
    "    azimuth = obsInfo.altaz_begin.az.value\n",
    "    # Time base in the EFD is still a big mess.  Although these times are in\n",
    "    # UTC, it is necessary to tell the code they are in TAI. Then it is\n",
    "    # necessary to tell the merge_packed_time_series to use UTC.\n",
    "    # After doing all of this, there is still a 2 second offset,\n",
    "    # which is discussed in JIRA ticket DM-29243, but not understood.\n",
    "\n",
    "    t_start = Time(tStart, scale='tai')\n",
    "    t_end = Time(tEnd, scale='tai')\n",
    "\n",
    "    mount_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_AzEl_Encoders\", t_start, t_end)\n",
    "    nasmyth_position = _getEfdData(client, \"lsst.sal.ATMCS.mount_Nasmyth_Encoders\", t_start, t_end)\n",
    "    torques = _getEfdData(client, \"lsst.sal.ATMCS.measuredTorque\", t_start, t_end)\n",
    "\n",
    "    az = mpts(mount_position, 'azimuthCalculatedAngle', stride=1)\n",
    "    el = mpts(mount_position, 'elevationCalculatedAngle', stride=1)\n",
    "    rot = mpts(nasmyth_position, 'nasmyth2CalculatedAngle', stride=1)\n",
    "    az_torque_1 = mpts(torques, 'azimuthMotor1Torque', stride=1)\n",
    "    az_torque_2 = mpts(torques, 'azimuthMotor2Torque', stride=1)\n",
    "    el_torque = mpts(torques, 'elevationMotorTorque', stride=1)\n",
    "    rot_torque = mpts(torques, 'nasmyth2MotorTorque', stride=1)\n",
    "\n",
    "    # Calculate the tracking errors\n",
    "    az_vals = np.array(az.values[:, 0])\n",
    "    el_vals = np.array(el.values[:, 0])\n",
    "    rot_vals = np.array(rot.values[:, 0])\n",
    "    times = np.array(az.values[:, 1])\n",
    "    # The fits are much better if the time variable\n",
    "    # is centered in the interval\n",
    "    fit_times = times - times[int(len(az.values[:, 1]) / 2)]\n",
    "\n",
    "    # Fit with a polynomial\n",
    "    az_fit = np.polyfit(fit_times, az_vals, 4)\n",
    "    el_fit = np.polyfit(fit_times, el_vals, 4)\n",
    "    rot_fit = np.polyfit(fit_times, rot_vals, 2)\n",
    "    az_model = np.polyval(az_fit, fit_times)\n",
    "    el_model = np.polyval(el_fit, fit_times)\n",
    "    rot_model = np.polyval(rot_fit, fit_times)\n",
    "\n",
    "    # Errors in arcseconds\n",
    "    az_error = (az_vals - az_model) * 3600\n",
    "    el_error = (el_vals - el_model) * 3600\n",
    "    rot_error = (rot_vals - rot_model) * 3600\n",
    "\n",
    "    # Calculate RMS\n",
    "    az_rms = np.sqrt(np.mean(az_error * az_error))\n",
    "    el_rms = np.sqrt(np.mean(el_error * el_error))\n",
    "    rot_rms = np.sqrt(np.mean(rot_error * rot_error))\n",
    "\n",
    "    # Calculate Image impact RMS\n",
    "    image_az_rms = az_rms * np.cos(el_vals[0] * np.pi / 180.0)\n",
    "    image_el_rms = el_rms\n",
    "    image_rot_rms = rot_rms * AUXTEL_ANGLE_TO_EDGE_OF_FIELD_ARCSEC * np.pi / 180.0 / 3600.0\n",
    "\n",
    "    # Calculate the FFT peaks\n",
    "    fft_peaks = []\n",
    "    for i, error in enumerate([az_error, el_error]):\n",
    "        # Number of samples in normalized_tone\n",
    "        N = len(error)\n",
    "        SAMPLE_RATE = 100 # Samples/sec\n",
    "        \n",
    "        yf = fft(error)\n",
    "        yf = yf[0:int(len(az_error)/2)]\n",
    "        xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "        xf = xf[0:int(len(error)/2)]\n",
    "        yf = np.abs(fft(error))\n",
    "        yf = yf[0:int(len(error)/2)]\n",
    "        max = np.max(yf)\n",
    "        peak_indices, peak_dict = find_peaks(yf, height=max/100) \n",
    "        peak_heights = peak_dict['peak_heights']\n",
    "        \n",
    "        for j in range(1,4):\n",
    "            peak_index = peak_indices[np.argpartition(peak_heights,-j)[-j]]\n",
    "            peak_freq = xf[peak_index]\n",
    "            height_index = np.where(peak_indices == peak_index)[0][0]\n",
    "            peak_height = peak_heights[height_index]\n",
    "            fft_peaks.append([peak_freq, peak_height])\n",
    "    return fft_peaks\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3581be2-b8bb-4e2b-92d4-56935e1c53e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T22:31:53.158549Z",
     "iopub.status.busy": "2023-11-30T22:31:53.157944Z",
     "iopub.status.idle": "2023-11-30T22:31:53.840952Z",
     "shell.execute_reply": "2023-11-30T22:31:53.840256Z",
     "shell.execute_reply.started": "2023-11-30T22:31:53.158530Z"
    }
   },
   "outputs": [],
   "source": [
    "expId = 2023110800415 # Oscillation\n",
    "#expId = 2023111600552 # Wind\n",
    "#expId = 2023111600561 # Crazy mount?\n",
    "#expId = 2023112000238 # Crazy mount?\n",
    "#expId = 2023112000201 # Shutter open too soon\n",
    "#expId = 2023110700594 # Timebase errors 1\n",
    "#expId = 2023110700519 # Timebase errors 2\n",
    "dataId = {'detector':0, 'exposure':expId}\n",
    "fft_peaks = calculateFFTPeaks(dataId, butler, client)\n",
    "print(fft_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d57a3-cae4-4d17-b83b-5b008d8368d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T14:38:38.345521Z",
     "iopub.status.busy": "2023-11-30T14:38:38.345242Z",
     "iopub.status.idle": "2023-11-30T14:38:38.349385Z",
     "shell.execute_reply": "2023-11-30T14:38:38.348753Z",
     "shell.execute_reply.started": "2023-11-30T14:38:38.345499Z"
    }
   },
   "outputs": [],
   "source": [
    "az_error = err['az_error']\n",
    "el_error = err['el_error']\n",
    "times = err['fit_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a52f7f-fe06-4124-8a94-cf29a300aee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T14:38:40.925057Z",
     "iopub.status.busy": "2023-11-30T14:38:40.924682Z",
     "iopub.status.idle": "2023-11-30T14:38:41.135551Z",
     "shell.execute_reply": "2023-11-30T14:38:41.135090Z",
     "shell.execute_reply.started": "2023-11-30T14:38:40.925029Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,4))\n",
    "for i, error in enumerate([az_error, el_error]):\n",
    "    # Number of samples in normalized_tone\n",
    "    N = len(error)\n",
    "    SAMPLE_RATE = 100 # Samples/sec\n",
    "    \n",
    "    yf = fft(error)\n",
    "    yf = yf[0:int(len(az_error)/2)]\n",
    "    xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "    xf = xf[0:int(len(error)/2)]\n",
    "    yf = np.abs(fft(error))\n",
    "    yf = yf[0:int(len(error)/2)]\n",
    "    max = np.max(yf)\n",
    "    peak_indices, peak_dict = find_peaks(yf, height=max/100) \n",
    "    peak_heights = peak_dict['peak_heights']\n",
    "    for j in range(1,4):\n",
    "        try:\n",
    "            peak_index = peak_indices[np.argpartition(peak_heights,-j)[-j]]\n",
    "            xplot = xf[peak_index]\n",
    "            height_index = np.where(peak_indices == peak_index)[0][0]\n",
    "            yplot = peak_heights[height_index]\n",
    "            print(peak_index, xplot, yplot)\n",
    "            axs[i].plot([xplot,xplot], [0,yplot], ls='--', color='black')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    axs[i].plot(xf, yf)\n",
    "    axs[i].set_xlim(0,10)\n",
    "    #axs[i].set_ylim(0,500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f46396-6c03-4b28-a970-756868c01896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
