{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2ad8f9-90c0-4b72-9cb5-b9b29eac8678",
   "metadata": {},
   "source": [
    "# Nightly Report: IQ, AOS, Thermal, Aberrations and Degrees of Freedom\n",
    "\n",
    "Owner: **Guillem Megias** <br>\n",
    "Last Verified to Run: **2025-07-07** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0fbcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:24:11.345543Z",
     "iopub.status.busy": "2025-11-25T14:24:11.345231Z",
     "iopub.status.idle": "2025-11-25T14:24:11.349543Z",
     "shell.execute_reply": "2025-11-25T14:24:11.348369Z",
     "shell.execute_reply.started": "2025-11-25T14:24:11.345518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Times Square Parameters\n",
    "day_obs = 20251124\n",
    "seq_min = 0\n",
    "seq_max = 900\n",
    "\n",
    "# This version has added back the bending modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7ca3a-b9f6-484c-9670-8534617bac0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:07:11.503050Z",
     "iopub.status.busy": "2025-11-23T18:07:11.502722Z",
     "iopub.status.idle": "2025-11-23T18:07:11.509770Z",
     "shell.execute_reply": "2025-11-23T18:07:11.508584Z",
     "shell.execute_reply.started": "2025-11-23T18:07:11.503023Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6ad69-410b-4729-860c-7ac6992b7d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T23:34:39.604746Z",
     "iopub.status.busy": "2025-11-21T23:34:39.604500Z",
     "iopub.status.idle": "2025-11-21T23:34:40.130025Z",
     "shell.execute_reply": "2025-11-21T23:34:40.129151Z",
     "shell.execute_reply.started": "2025-11-21T23:34:39.604722Z"
    }
   },
   "outputs": [],
   "source": [
    "import galsim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "def getPsfGradPerZernike(\n",
    "    diameter: float = 8.36,\n",
    "    obscuration: float = 0.612,\n",
    "    jmin: int = 4,\n",
    "    jmax: int = 22,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Get the gradient of the PSF FWHM with respect to each Zernike.\n",
    "\n",
    "    This function takes no positional arguments. All parameters must be passed\n",
    "    by name (see the list of parameters below).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diameter : float, optional\n",
    "        The diameter of the telescope aperture, in meters.\n",
    "        (the default, 8.36, corresponds to the LSST primary mirror)\n",
    "    obscuration : float, optional\n",
    "        Central obscuration of telescope aperture (i.e. R_outer / R_inner).\n",
    "        (the default, 0.612, corresponds to the LSST primary mirror)\n",
    "    jmin : int, optional\n",
    "        The minimum Noll index, inclusive. Must be >= 0. (the default is 4)\n",
    "    jmax : int, optional\n",
    "        The max Zernike Noll index, inclusive. Must be >= jmin.\n",
    "        (the default is 22.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Gradient of the PSF FWHM with respect to the corresponding Zernike.\n",
    "        Units are arcsec / micron.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If jmin is negative or jmax is less than jmin\n",
    "    \"\"\"\n",
    "    # Check jmin and jmax\n",
    "    if jmin < 0:\n",
    "        raise ValueError(\"jmin cannot be negative.\")\n",
    "    if jmax < jmin:\n",
    "        raise ValueError(\"jmax must be greater than jmin.\")\n",
    "\n",
    "    # Calculate the conversion factors\n",
    "    conversion_factors = np.zeros(jmax + 1)\n",
    "    for i in range(jmin, jmax + 1):\n",
    "        # Set coefficients for this Noll index: coefs = [0, 0, ..., 1]\n",
    "        # Note the first coefficient is Noll index 0, which does not exist and\n",
    "        # is therefore always ignored by galsim\n",
    "        coefs = [0] * i + [1]\n",
    "\n",
    "        # Create the Zernike polynomial with these coefficients\n",
    "        R_outer = diameter / 2\n",
    "        R_inner = R_outer * obscuration\n",
    "        Z = galsim.zernike.Zernike(coefs, R_outer=R_outer, R_inner=R_inner)\n",
    "\n",
    "        # We can calculate the size of the PSF from the RMS of the gradient of\n",
    "        # the wavefront. The gradient of the wavefront perturbs photon paths.\n",
    "        # The RMS quantifies the size of the collective perturbation.\n",
    "        # If we expand the wavefront gradient in another series of Zernike\n",
    "        # polynomials, we can exploit the orthonormality of the Zernikes to\n",
    "        # calculate the RMS from the Zernike coefficients.\n",
    "        rms_tilt = np.sqrt(np.sum(Z.gradX.coef**2 + Z.gradY.coef**2) / 2)\n",
    "\n",
    "        # Convert to arcsec per micron\n",
    "        rms_tilt = np.rad2deg(rms_tilt * 1e-6) * 3600\n",
    "\n",
    "        # Convert rms -> fwhm\n",
    "        fwhm_tilt = 2 * np.sqrt(2 * np.log(2)) * rms_tilt\n",
    "\n",
    "        # Save this conversion factor\n",
    "        conversion_factors[i] = fwhm_tilt\n",
    "\n",
    "    return conversion_factors[jmin:]\n",
    "\n",
    "\n",
    "def convertZernikesToPsfWidth(\n",
    "    zernikes: np.ndarray,\n",
    "    diameter: float = 8.36,\n",
    "    obscuration: float = 0.612,\n",
    "    jmin: int = 4,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Convert Zernike amplitudes to quadrature contribution to the PSF FWHM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zernikes : np.ndarray\n",
    "        Zernike amplitudes (in microns), starting with Noll index `jmin`.\n",
    "        Either a 1D array of zernike amplitudes, or a 2D array, where each row\n",
    "        corresponds to a different set of amplitudes.\n",
    "    diameter : float\n",
    "        The diameter of the telescope aperture, in meters.\n",
    "        (the default, 8.36, corresponds to the LSST primary mirror)\n",
    "    obscuration : float\n",
    "        Central obscuration of telescope aperture (i.e. R_outer / R_inner).\n",
    "        (the default, 0.612, corresponds to the LSST primary mirror)\n",
    "    jmin : int\n",
    "        The minimum Zernike Noll index, inclusive. Must be >= 0. The\n",
    "        max Noll index is inferred from `jmin` and the length of `zernikes`.\n",
    "        (the default is 4, which ignores piston, x & y offsets, and tilt.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dFWHM: np.ndarray\n",
    "        Quadrature contribution of each Zernike vector to the PSF FWHM\n",
    "        (in arcseconds).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Converting Zernike amplitudes to their quadrature contributions to the PSF\n",
    "    FWHM allows for easier physical interpretation of Zernike amplitudes and\n",
    "    the performance of the AOS system.\n",
    "\n",
    "    For example, image we have a true set of zernikes, [Z4, Z5, Z6], such that\n",
    "    ConvertZernikesToPsfWidth([Z4, Z5, Z6]) = [0.1, -0.2, 0.3] arcsecs.\n",
    "    These Zernike perturbations increase the PSF FWHM by\n",
    "    sqrt[(0.1)^2 + (-0.2)^2 + (0.3)^2] ~ 0.37 arcsecs.\n",
    "\n",
    "    If the AOS perfectly corrects for these perturbations, the PSF FWHM will\n",
    "    not increase in size. However, imagine the AOS estimates zernikes, such\n",
    "    that ConvertZernikesToPsfWidth([Z4, Z5, Z6]) = [0.1, -0.3, 0.4] arcsecs.\n",
    "    These estimated Zernikes, do not exactly match the true Zernikes above.\n",
    "    Therefore, the post-correction PSF will still be degraded with respect to\n",
    "    the optimal PSF. In particular, the PSF FWHM will be increased by\n",
    "    sqrt[(0.1 - 0.1)^2 + (-0.2 - (-0.3))^2 + (0.3 - 0.4)^2] ~ 0.14 arcsecs.\n",
    "\n",
    "    This conversion depends on a linear approximation that begins to break down\n",
    "    for RSS(dFWHM) > 0.20 arcsecs. Beyond this point, the approximation tends\n",
    "    to overestimate the PSF degradation. In other words, if\n",
    "    sqrt(sum( dFWHM^2 )) > 0.20 arcsec, it is likely that dFWHM is\n",
    "    over-estimated. However, the point beyond which this breakdown begins\n",
    "    (and whether the approximation over- or under-estimates dFWHM) can change,\n",
    "    depending on which Zernikes have large amplitudes. In general, if you have\n",
    "    large Zernike amplitudes, proceed with caution!\n",
    "    Note that if the amplitudes Z_est and Z_true are large, this is okay, as\n",
    "    long as |Z_est - Z_true| is small.\n",
    "\n",
    "    For a notebook demonstrating where the approximation breaks down:\n",
    "    https://gist.github.com/jfcrenshaw/24056516cfa3ce0237e39507674a43e1\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If jmin is negative\n",
    "    \"\"\"\n",
    "    # Check jmin\n",
    "    if jmin < 0:\n",
    "        raise ValueError(\"jmin cannot be negative.\")\n",
    "\n",
    "    # Calculate jmax from jmin and the length of the zernike array\n",
    "    jmax = jmin + np.array(zernikes).shape[-1] - 1\n",
    "\n",
    "    # Calculate the conversion factors for each zernike\n",
    "    conversion_factors = getPsfGradPerZernike(\n",
    "        jmin=jmin,\n",
    "        jmax=jmax,\n",
    "        diameter=diameter,\n",
    "        obscuration=obscuration,\n",
    "    )\n",
    "\n",
    "    # Convert the Zernike amplitudes from microns to their quadrature\n",
    "    # contribution to the PSF FWHM\n",
    "    dFWHM = conversion_factors * zernikes\n",
    "\n",
    "    return dFWHM\n",
    "\n",
    "band_colors = {\n",
    "    \"u\": \"#0c71ff\",\n",
    "    \"g\": \"#49be61\",\n",
    "    \"r\": \"#c61c00\",\n",
    "    \"i\": \"#ffc200\",\n",
    "    \"z\": \"#f341a2\",\n",
    "    \"y\": \"#5d0000\",\n",
    "}\n",
    "    \n",
    "def annotate_bands(data: pd.DataFrame, ax: plt.Axes) -> None:\n",
    "    \"\"\"Anotate bottom of plot with band colors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Table of data that is being plotted\n",
    "    ax : plt.Axes\n",
    "        Axis on which to add annotations\n",
    "    \"\"\"\n",
    "    # Get the bands\n",
    "    bands = data['band']\n",
    "\n",
    "    # Get the axis limits\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # Plot band bars at bottom of plot\n",
    "    max_seq = data.index[-1]\n",
    "    for i, band in enumerate(bands[:-1]):\n",
    "        ax.plot(\n",
    "            data.index[i : i + 2],\n",
    "            2 * [ylim[0]],\n",
    "            c=band_colors[band[0]],\n",
    "            lw=7,\n",
    "        )\n",
    "    # Do something special for last one\n",
    "    ax.plot(\n",
    "        [data.index[-1], data.index[-1]+1],\n",
    "        2 * [ylim[0]],\n",
    "        c=band_colors[bands.iloc[-1][0]],\n",
    "        lw=7,\n",
    "    )\n",
    "\n",
    "    # Restore the axis limits\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlim(xlim)\n",
    "\n",
    "    # Add unique bands to legend\n",
    "    unique_bands = data['band'].str[0].unique()  # Get first character of each band\n",
    "    \n",
    "    for band_char in sorted(unique_bands):\n",
    "        ax.scatter([], [], \n",
    "                  c=band_colors[band_char], \n",
    "                  s=100, \n",
    "                  marker='s', \n",
    "                  label=f'{band_char}')\n",
    "\n",
    "def find_blocks(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Find blocks active during the night\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Table of data that is being plotted\n",
    "    Returns\n",
    "    -------\n",
    "    changes: pd.DataFrame\n",
    "        dataframe containing the sequence numbers where the block changed\n",
    "        and the name of the new block\n",
    "    \"\"\"\n",
    "    block_data = data[['seq', 'block']].sort_values(by='seq')\n",
    "    change_mask = block_data['block'] != block_data['block'].shift()\n",
    "    block_data['block'] = block_data['block'].str.replace('BLOCK-', '', regex=False)\n",
    "    blocks = pd.DataFrame({\n",
    "        'seq': block_data.loc[change_mask, 'seq'],\n",
    "        'block_after': block_data['block'].loc[change_mask]\n",
    "    })\n",
    "    return blocks\n",
    "\n",
    "async def find_faults(client, table):\n",
    "    \"\"\"Find faults during the night\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client: EFD client\n",
    "    table : pd.DataFrame\n",
    "        Table of data that is being plotted\n",
    "    Returns\n",
    "    -------\n",
    "    table: pd.DataFrame\n",
    "        incoming dataframe with the fault events added\n",
    "    \"\"\"\n",
    "    table_time = pd.to_datetime(table['time'], format='ISO8601', utc=True)\n",
    "    topics = ['MTMount', 'MTAOS', 'MTHexapod', 'MTCamera']\n",
    "    table['faults'] = [None for i in range(len(table))]\n",
    "    start = Time(table['obs_start'].iloc[0])\n",
    "    end = Time(table['obs_end'].iloc[-1])\n",
    "    for topic in topics:\n",
    "        efd_data = await client.select_time_series(f\"lsst.sal.{topic}.logevent_summaryState\", \\\n",
    "                                                ['summaryState'], \\\n",
    "                                                 start, end)\n",
    "        if len(efd_data) == 0:\n",
    "            continue\n",
    "        faults = efd_data[efd_data['summaryState'] == 3]\n",
    "        for i in range(len(faults)):\n",
    "            fault_time = pd.to_datetime(faults.index[i], format='utc')\n",
    "            closest_row = table.iloc[(table_time - fault_time).abs().argmin()]\n",
    "            table.loc[table['seq'] == closest_row['seq'], 'faults'] = topic\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb37f5-2f59-44fb-a4a2-61011a7af6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T23:34:40.142917Z",
     "iopub.status.busy": "2025-11-21T23:34:40.142693Z",
     "iopub.status.idle": "2025-11-21T23:34:42.824298Z",
     "shell.execute_reply": "2025-11-21T23:34:42.823196Z",
     "shell.execute_reply.started": "2025-11-21T23:34:40.142895Z"
    }
   },
   "outputs": [],
   "source": [
    "from lsst.ts.xml.tables.m1m3 import *\n",
    "from lsst.ts.m1m3.utils import *\n",
    "\n",
    "\n",
    "async def get_m1m3_gradients(client, data):\n",
    "    \"\"\"Get the M1M3 thermal gradients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    client: EFD client\n",
    "    data : pd.DataFrame\n",
    "        Table of minimal data\n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.DataFrame\n",
    "        incoming dataframe with the m1m3 temperature gradients added\n",
    "    \"\"\"\n",
    "    data_times = pd.to_datetime(data['obs_start'], format='ISO8601', utc=True)\n",
    "    sorted_data_times = data_times.sort_values()\n",
    "    start = Time(sorted_data_times.iloc[0])\n",
    "    end = Time(sorted_data_times.iloc[-1])\n",
    "    data_times = data_times.astype('int64')\n",
    "    thermocouples = ThermocoupleAnalysis(client)\n",
    "    await thermocouples.load(start, end, time_bin=30)\n",
    "    gradients = thermocouples.xyz_r_gradients\n",
    "    grad_times = pd.to_datetime(gradients.index, format='ISO8601', utc=True).astype('int64')\n",
    "    t0 = grad_times[0]\n",
    "    grad_times -= t0\n",
    "    grad_times /=1E9\n",
    "    data_times -= t0\n",
    "    data_times /= 1E9\n",
    "    names = ['x_gradient', 'y_gradient', 'z_gradient', 'radial_gradient']\n",
    "    for name in names:\n",
    "        values = gradients[name].values\n",
    "        val_series = pd.Series(values)\n",
    "        val_interpolated = val_series.interpolate()\n",
    "        data[name] = np.interp(data_times, grad_times, val_interpolated)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b374fd8-cc1d-4ff8-868b-326792aaf847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T23:34:42.826026Z",
     "iopub.status.busy": "2025-11-21T23:34:42.825725Z",
     "iopub.status.idle": "2025-11-21T23:34:42.837467Z",
     "shell.execute_reply": "2025-11-21T23:34:42.836529Z",
     "shell.execute_reply.started": "2025-11-21T23:34:42.826001Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_m1m3_gradients(data, ax):\n",
    "    \"\"\"Plot the M1M3 thermal gradients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Table of data to plot\n",
    "    ax : matplotlib.axes._axes.Axes\n",
    "        axes object on which to plot the data\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Palettes: same hue family within groups, distinct shades per line ---\n",
    "    blues   = plt.get_cmap('Blues')\n",
    "    oranges = plt.get_cmap('Oranges')\n",
    "    \n",
    "    # Line colors (distinct, but clearly grouped)\n",
    "    c_x = blues(0.75)     # darker blue\n",
    "    c_y = blues(0.55)     # lighter blue\n",
    "    c_r = oranges(0.75)   # darker orange\n",
    "    c_z = oranges(0.55)   # lighter orange\n",
    "    \n",
    "    # Band colors (very light tint of the group hue)\n",
    "    band_xy = blues(0.25)\n",
    "    band_rz = oranges(0.25)\n",
    "    \n",
    "    # --- Shaded operational bands (put behind data) ---\n",
    "    ax.axhspan(-0.4, 0.4, facecolor=band_xy, alpha=0.3, zorder=0)\n",
    "    ax.axhspan(-0.1, 0.1, facecolor=band_rz, alpha=0.3, zorder=0)\n",
    "    ax.axhline(0.4,  color=blues(0.65), linestyle=\"-\", linewidth=1, alpha=0.5)\n",
    "    ax.axhline(-0.4, color=blues(0.65), linestyle=\"-\", linewidth=1, alpha=0.5)\n",
    "    ax.axhline(0.1,  color=oranges(0.65), linestyle=\"-\", linewidth=1, alpha=0.5)\n",
    "    ax.axhline(-0.1, color=oranges(0.65), linestyle=\"-\", linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # --- Data lines: distinct per series with styles/markers ---\n",
    "    ax.scatter(data['seq'],\n",
    "        data['x_gradient'] * 8.4,\n",
    "        label=\"X (×8.4)\", color=c_x, linewidth=2.0, linestyle=\"-\",\n",
    "        s=0.5, zorder=3\n",
    "    )\n",
    "    ax.scatter(data['seq'],\n",
    "        data['y_gradient'] * 8.4,\n",
    "        label=\"Y (×8.4)\", color=c_y, linewidth=2.0, linestyle=\"--\",\n",
    "        s=0.5, zorder=3\n",
    "    )\n",
    "    ax.scatter(data['seq'],\n",
    "        data['radial_gradient'] * 4.2,\n",
    "        label=\"Radial (×4.2)\", color=c_r, linewidth=2.0, linestyle=\"-\",\n",
    "        s=0.5, zorder=4\n",
    "    )\n",
    "    ax.scatter(data['seq'],\n",
    "        data['z_gradient'],\n",
    "        label=\"Z\", color=c_z, linewidth=2.0, linestyle=\"--\",\n",
    "        s=0.5, zorder=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # --- Legends: one for data lines, one for bands (with matching colors) ---\n",
    "    data_leg = ax.legend(bbox_to_anchor=(0.0, 1.25), loc='upper left',\n",
    "                frameon=True, ncol=2, markerscale=4)\n",
    "    ax.add_artist(data_leg)\n",
    "    \n",
    "    band_handles = [\n",
    "        Patch(facecolor=band_xy, alpha=0.6, label=\"X/Y limit band (±0.4)\"),\n",
    "        Patch(facecolor=band_rz, alpha=0.6, label=\"Radial/Z limit band (±0.1)\"),\n",
    "    ]\n",
    "    ax.legend(handles=band_handles,\n",
    "              loc=\"upper right\", frameon=True, bbox_to_anchor=(1.0, 1.25))\n",
    "    \n",
    "    # --- Labels, grid, cosmetics ---\n",
    "    \n",
    "    ax.set_ylim(-0.6, 0.6)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3430178-15c4-4de1-800f-0bf847e2f330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T23:34:43.751065Z",
     "iopub.status.busy": "2025-11-21T23:34:43.750736Z",
     "iopub.status.idle": "2025-11-21T23:34:56.345961Z",
     "shell.execute_reply": "2025-11-21T23:34:56.344867Z",
     "shell.execute_reply.started": "2025-11-21T23:34:43.751038Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "from lsst.obs.lsst import LsstCam\n",
    "from lsst.summit.utils import (\n",
    "    ConsDbClient,\n",
    "    getAirmassSeeingCorrection,\n",
    "    getBandpassSeeingCorrection,\n",
    ")\n",
    "from lsst.summit.utils.efdUtils import (\n",
    "    getEfdData,\n",
    "    getMostRecentRowWithDataBefore,\n",
    "    makeEfdClient,\n",
    ")\n",
    "from lsst.ts.ofc import BendModeToForce, OFCData, StateEstimator\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "__all__ = [\"AOSDatabase\"]\n",
    "\n",
    "\n",
    "class AOSDatabase:\n",
    "    table: pd.DataFrame\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        day_obs: int = 20250415,\n",
    "        seq_min: int = 1,\n",
    "        seq_max: int = 9999,\n",
    "        consdb_url: str = \"http://consdb-pq.consdb:8080/consdb\",\n",
    "    ) -> None:\n",
    "        \"\"\"Create fetcher.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seq_max : int, optional\n",
    "            Maximum sequence number to fetch. Default is 9999.\n",
    "        consdb_url : str, optional\n",
    "            URL to create ConsDB client.\n",
    "            The default is \"http://consdb-pq.consdb:8080/consdb\".\n",
    "        \"\"\"\n",
    "        self.log = logging.getLogger(__name__)\n",
    "\n",
    "        self.efd_client = makeEfdClient()\n",
    "        self.cdb_client = ConsDbClient(consdb_url)\n",
    "\n",
    "        self.det_order = list([191, 195, 199, 203])\n",
    "        camera = LsstCam().getCamera()\n",
    "        self.detector_names = [\n",
    "            camera.get(det_id).getName() for det_id in self.det_order\n",
    "        ]\n",
    "\n",
    "        self.day_obs = day_obs\n",
    "        self.seq_max = seq_max\n",
    "        self.seq_min = seq_min\n",
    "        self.table = pd.DataFrame()\n",
    "\n",
    "        self.time_window = TimeDelta(0.2, format=\"sec\")\n",
    "        self.temp_time_window = TimeDelta(0.2, format=\"sec\")\n",
    "\n",
    "        self.ofc_data = OFCData(\"lsst\")\n",
    "        self.m2_bmf = BendModeToForce(\"M2\", self.ofc_data)\n",
    "        self.m1m3_bmf = BendModeToForce(\"M1M3\", self.ofc_data)\n",
    "\n",
    "    async def create(self, simplified=False):\n",
    "        self.table = await self._fetch(\n",
    "            self.day_obs, self.seq_min, self.seq_max, simplified\n",
    "        )\n",
    "\n",
    "    async def update(self, simplified: bool = False) -> None:\n",
    "        \"\"\"Update the database by grabbing more recent exposures.\n",
    "        This will only grab new sequences, not re-fetch existing ones.\n",
    "        \"\"\"\n",
    "        # First grab new sequences\n",
    "        seq_min = self.table[\"seq\"].max() + 1\n",
    "        updated_table = await self._fetch(\n",
    "            self.day_obs, seq_min, self.seq_max, simplified=simplified\n",
    "        )\n",
    "        self.table = pd.concat(\n",
    "            [self.table, updated_table],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "    async def _fetch(\n",
    "        self, day_obs: int, seq_min: int, seq_max: int, simplified: bool = False\n",
    "    ) -> pd.DataFrame:\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "            e.air_temp AS air_temp,\n",
    "            e.airmass AS airmass,\n",
    "            e.dimm_seeing AS dimm,\n",
    "            e.altitude AS elevation,\n",
    "            e.azimuth AS azimuth,\n",
    "            e.exposure_id AS visit_id,\n",
    "            e.physical_filter as band,\n",
    "            e.day_obs AS day_obs,\n",
    "            e.exp_midpt AS time,\n",
    "            e.dimm_seeing AS seeing,\n",
    "            e.seq_num AS seq,\n",
    "            e.science_program AS block,\n",
    "            ccdvisit1_quicklook.psf_sigma,\n",
    "            ccdvisit1_quicklook.z4,\n",
    "            ccdvisit1_quicklook.z5,\n",
    "            ccdvisit1_quicklook.z6,\n",
    "            ccdvisit1_quicklook.z7,\n",
    "            ccdvisit1_quicklook.z8,\n",
    "            ccdvisit1_quicklook.z9,\n",
    "            ccdvisit1_quicklook.z10,\n",
    "            ccdvisit1_quicklook.z11,\n",
    "            ccdvisit1_quicklook.z12,\n",
    "            ccdvisit1_quicklook.z13,\n",
    "            ccdvisit1_quicklook.z14,\n",
    "            ccdvisit1_quicklook.z15,\n",
    "            ccdvisit1_quicklook.z16,\n",
    "            ccdvisit1_quicklook.z17,\n",
    "            ccdvisit1_quicklook.z18,\n",
    "            ccdvisit1_quicklook.z19,\n",
    "            ccdvisit1_quicklook.z20,\n",
    "            ccdvisit1_quicklook.z21,\n",
    "            ccdvisit1_quicklook.z22,\n",
    "            ccdvisit1_quicklook.z23,\n",
    "            ccdvisit1_quicklook.z24,\n",
    "            ccdvisit1_quicklook.z25,\n",
    "            ccdvisit1_quicklook.z26,\n",
    "            ccdvisit1_quicklook.z27,\n",
    "            ccdvisit1_quicklook.z28,\n",
    "            ccdvisit1.detector as detector,\n",
    "            q.psf_sigma_median AS psf_fwhm,\n",
    "            q.aos_fwhm AS aos_fwhm,\n",
    "            q.donut_blur_fwhm AS donut_blur_fwhm,\n",
    "            q.physical_rotator_angle AS rotation_angle,\n",
    "            e.obs_end,\n",
    "            e.obs_start\n",
    "            FROM\n",
    "            cdb_lsstcam.ccdvisit1_quicklook AS ccdvisit1_quicklook,\n",
    "            cdb_lsstcam.ccdvisit1 AS ccdvisit1,\n",
    "            cdb_lsstcam.visit1 AS visit1,\n",
    "            cdb_lsstcam.visit1_quicklook AS q,\n",
    "            cdb_lsstcam.exposure AS e\n",
    "            WHERE\n",
    "            ccdvisit1.detector IN (191, 192, 195, 196, 199, 200, 203, 204)\n",
    "            AND ccdvisit1.ccdvisit_id = ccdvisit1_quicklook.ccdvisit_id\n",
    "            AND ccdvisit1.visit_id = visit1.visit_id\n",
    "            AND ccdvisit1.visit_id = q.visit_id\n",
    "            AND ccdvisit1.visit_id = e.exposure_id\n",
    "            AND (e.img_type = 'science' or e.img_type = 'acq' or e.img_type = 'engtest')\n",
    "            AND e.day_obs = {day_obs}\n",
    "            AND (e.seq_num BETWEEN {seq_min} AND {seq_max})\n",
    "            AND e.airmass > 0\n",
    "            AND e.band != 'none'\n",
    "        \"\"\"\n",
    "        self.table = self.cdb_client.query(query).to_pandas()\n",
    "\n",
    "        # Correctly declare aos_fwhm and donut_blur_fwhm as float\n",
    "        self.table['aos_fwhm'] = pd.to_numeric(self.table['aos_fwhm'])\n",
    "        self.table['donut_blur_fwhm'] = pd.to_numeric(self.table['donut_blur_fwhm'])\n",
    "\n",
    "        # Convert PSF sigma to FWHM\n",
    "        sig2fwhm = 2 * np.sqrt(2 * np.log(2))\n",
    "        pixel_scale = 0.2  # arcsec / pixel\n",
    "        self.table[\"psf_fwhm\"] = self.table[\"psf_fwhm\"] * sig2fwhm * pixel_scale\n",
    "\n",
    "        self.table[\"fwhm_zenith_500nm\"] = [\n",
    "            fwhm\n",
    "            * getAirmassSeeingCorrection(airmass)\n",
    "            * getBandpassSeeingCorrection(band)\n",
    "            for fwhm, band, airmass in zip(\n",
    "                self.table[\"psf_fwhm\"], self.table[\"band\"], self.table[\"airmass\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        zernike_columns = [f\"z{i}\" for i in range(4, 29)]\n",
    "        self.table[\"zernikes\"] = self.table[zernike_columns].apply(\n",
    "            lambda row: np.array(row.fillna(0.0).values, dtype=float), axis=1\n",
    "        )\n",
    "        self.table[\"zernikes_fwhm\"] = self.table[\"zernikes\"].apply(\n",
    "            convertZernikesToPsfWidth\n",
    "        )\n",
    "        \n",
    "        # Get the data for the science CCDs for fwhm_05 and fwhm_95\n",
    "        visits_query = f'''\n",
    "        SELECT \n",
    "        ccdvisit1_quicklook.psf_sigma,\n",
    "        ccdvisit1.detector,\n",
    "        visit1.visit_id,\n",
    "        visit1.seq_num AS seq,\n",
    "        visit1.day_obs,\n",
    "        visit1.airmass\n",
    "        FROM\n",
    "        cdb_lsstcam.ccdvisit1_quicklook AS ccdvisit1_quicklook,\n",
    "        cdb_lsstcam.ccdvisit1 AS ccdvisit1,\n",
    "        cdb_lsstcam.visit1_quicklook AS visit1_quicklook,\n",
    "        cdb_lsstcam.visit1 AS visit1 \n",
    "        WHERE \n",
    "        ccdvisit1.ccdvisit_id = ccdvisit1_quicklook.ccdvisit_id\n",
    "        AND ccdvisit1.visit_id = visit1.visit_id \n",
    "        AND visit1.visit_id = visit1_quicklook.visit_id\n",
    "        AND ccdvisit1.detector NOT IN (168, 188, 123, 27, 0, 20, 65, 161)\n",
    "        AND visit1.airmass > 0\n",
    "        AND visit1.day_obs = {self.day_obs}\n",
    "        AND (visit1.seq_num BETWEEN {self.seq_min} AND {self.seq_max})\n",
    "        AND (visit1.img_type = 'science' or visit1.img_type = 'acq' or visit1.img_type = 'engtest')\n",
    "        '''\n",
    "        \n",
    "        ccdvisits = self.cdb_client.query(visits_query).to_pandas()\n",
    "        ccdvisits[\"psf_fwhm\"] = ccdvisits[\"psf_sigma\"] * sig2fwhm * pixel_scale\n",
    "        ccdvisits[\"psf_fwhm\"] = pd.to_numeric(ccdvisits[\"psf_fwhm\"], errors=\"coerce\")\n",
    "        groups = ccdvisits.groupby('visit_id')\n",
    "        visits_summary = pd.DataFrame({\n",
    "            'day_obs': groups['day_obs'].first(),\n",
    "            'seq': groups['seq'].median(),\n",
    "            'psf_fwhm_05': groups['psf_fwhm'].quantile(0.05),\n",
    "            'psf_fwhm_95': groups['psf_fwhm'].quantile(0.95),\n",
    "        })\n",
    "        visits_summary['psf_fwhm_95_05'] = np.sqrt(visits_summary['psf_fwhm_95']**2 - visits_summary['psf_fwhm_05']**2)\n",
    "        self.table = pd.merge(\n",
    "                        self.table, visits_summary, how=\"left\", on=[\"seq\", \"day_obs\"])\n",
    "        \n",
    "        self.table = await find_faults(self.efd_client, self.table)\n",
    "        \n",
    "        if not simplified:\n",
    "            unique_day_seq = (\n",
    "                self.table[[\"day_obs\", \"seq\", \"obs_end\", \"obs_start\"]]\n",
    "                .drop_duplicates()\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            (\n",
    "                inside_air_temp,\n",
    "                days,\n",
    "                seqs,\n",
    "                lut,\n",
    "                cam_air_temp,\n",
    "                states,\n",
    "                above_m1m3_temp,\n",
    "                outside_temp,\n",
    "                m2_temp,\n",
    "                correction_seq,\n",
    "            ) = ([] for _ in range(10))\n",
    "            for idx, row in tqdm(unique_day_seq.iterrows(), total=len(unique_day_seq), disable=True):\n",
    "                day_obs = int(row[\"day_obs\"])\n",
    "                seq = int(row[\"seq\"])\n",
    "\n",
    "                rec_end = row[\"obs_end\"]\n",
    "                rec_start = row[\"obs_start\"]\n",
    "\n",
    "                # ---------- Environment variables -------------\n",
    "                # ----------------------------------------------\n",
    "                # Get state\n",
    "                try:\n",
    "                    total_lut_gravity = [f\"lutGravity{i}\" for i in range(72)]\n",
    "                    total_lut_temperature = [f\"lutTemperature{i}\" for i in range(72)]\n",
    "                    m2_actuator_data = await self.efd_client.select_time_series(\n",
    "                        \"lsst.sal.MTM2.axialForce\",\n",
    "                        [\"*\"],\n",
    "                        Time(rec_start, scale=\"utc\"),\n",
    "                        Time(rec_start, scale=\"utc\") + self.time_window,\n",
    "                        convert_influx_index=True\n",
    "                    )\n",
    "    \n",
    "                    m2_combined_lut = (\n",
    "                        m2_actuator_data[total_lut_gravity].values\n",
    "                        + m2_actuator_data[total_lut_temperature].values\n",
    "                    )\n",
    "                    m2_combined_lut = m2_combined_lut.mean(axis=0)\n",
    "                    m2_dofs_lut = self.m2_bmf.bending_mode(m2_combined_lut)\n",
    "                except Exception:\n",
    "                    m2_dofs_lut = np.full(20, np.nan)\n",
    "\n",
    "                try:\n",
    "                    z_cols = [f\"zForces{i}\" for i in range(156)]\n",
    "                    m1m3_el_lut = await self.efd_client.select_time_series(\n",
    "                        \"lsst.sal.MTM1M3.appliedElevationForces\",\n",
    "                        z_cols,\n",
    "                        Time(rec_start, scale=\"utc\"),\n",
    "                        Time(rec_start, scale=\"utc\") + self.time_window,\n",
    "                        convert_influx_index=True\n",
    "                    )\n",
    "                    m1m3_el_lut = m1m3_el_lut[z_cols].values.mean(axis=0)\n",
    "\n",
    "                    m1m3_az_lut = await self.efd_client.select_time_series(\n",
    "                        \"lsst.sal.MTM1M3.appliedAzimuthForces\",\n",
    "                        z_cols,\n",
    "                        Time(rec_start, scale=\"utc\"),\n",
    "                        Time(rec_start, scale=\"utc\") + self.time_window,\n",
    "                        convert_influx_index=True\n",
    "                    )\n",
    "                    m1m3_az_lut = m1m3_az_lut[z_cols].values.mean(axis=0)\n",
    "\n",
    "                    m1m3_temp_lut = await self.efd_client.select_time_series(\n",
    "                        \"lsst.sal.MTM1M3.appliedThermalForces\",\n",
    "                        z_cols,\n",
    "                        Time(rec_start, scale=\"utc\"),\n",
    "                        Time(rec_start, scale=\"utc\") + self.time_window,\n",
    "                        convert_influx_index=True\n",
    "                    )\n",
    "                    m1m3_temp_lut = m1m3_temp_lut[z_cols].values.mean(axis=0)\n",
    "\n",
    "                    # Align the three DataFrames\n",
    "                    # (assumes same shape/timestamps)\n",
    "                    m1m3_combined_lut = m1m3_el_lut + m1m3_az_lut + m1m3_temp_lut\n",
    "                    m1m3_combined_lut = m1m3_combined_lut\n",
    "                    m1m3_dofs_lut = self.m1m3_bmf.bending_mode(m1m3_combined_lut)\n",
    "                except Exception:\n",
    "                    m1m3_dofs_lut = np.full(20, np.nan)\n",
    "                try:                    \n",
    "                    cam_hexapod_data = getMostRecentRowWithDataBefore(\n",
    "                        self.efd_client,\n",
    "                        \"lsst.sal.MTHexapod.logevent_compensationOffset\",\n",
    "                        Time(rec_end, scale=\"utc\"),\n",
    "                        maxSearchNMinutes=10,\n",
    "                        where=lambda df: df[\"salIndex\"] == 1,\n",
    "                    )\n",
    "\n",
    "                    m2_hexapod_data = getMostRecentRowWithDataBefore(\n",
    "                        self.efd_client,\n",
    "                        \"lsst.sal.MTHexapod.logevent_compensationOffset\",\n",
    "                        Time(rec_end, scale=\"utc\"),\n",
    "                        maxSearchNMinutes=10,\n",
    "                        where=lambda df: df[\"salIndex\"] == 2,\n",
    "                    )\n",
    "\n",
    "                    hexapod_val = np.array(\n",
    "                        [\n",
    "                            m2_hexapod_data[\"z\"],\n",
    "                            m2_hexapod_data[\"x\"],\n",
    "                            m2_hexapod_data[\"y\"],\n",
    "                            m2_hexapod_data[\"u\"],\n",
    "                            m2_hexapod_data[\"v\"],\n",
    "                            cam_hexapod_data[\"z\"],\n",
    "                            cam_hexapod_data[\"x\"],\n",
    "                            cam_hexapod_data[\"y\"],\n",
    "                            cam_hexapod_data[\"u\"],\n",
    "                            cam_hexapod_data[\"v\"],\n",
    "                        ]\n",
    "                    )\n",
    "                    lut_val = np.concatenate([hexapod_val, m1m3_dofs_lut, m2_dofs_lut])\n",
    "                except Exception:\n",
    "                    lut_val = np.full(50, np.nan)\n",
    "\n",
    "                event = getMostRecentRowWithDataBefore(\n",
    "                    self.efd_client,\n",
    "                    \"lsst.sal.MTAOS.logevent_degreeOfFreedom\",\n",
    "                    timeToLookBefore=Time(rec_start, scale=\"utc\"),\n",
    "                )\n",
    "                out = np.empty(\n",
    "                    50,\n",
    "                )\n",
    "                for i in range(50):\n",
    "                    out[i] = event[f\"aggregatedDoF{i}\"]\n",
    "                states_val = out\n",
    "\n",
    "                seq_num_corr = event[\"visitId\"]\n",
    "                \n",
    "                # Get outside temperature\n",
    "                temp_outside_data = await self.efd_client.select_time_series(\n",
    "                    \"lsst.sal.ESS.temperature\",\n",
    "                    [\"temperatureItem0\"],\n",
    "                    Time(rec_start, scale=\"utc\"),\n",
    "                    Time(rec_end, scale=\"utc\") + self.temp_time_window,\n",
    "                    index=301,\n",
    "                    convert_influx_index=True\n",
    "                )\n",
    "                if \"temperatureItem0\" in temp_outside_data:\n",
    "                    outside_temp_val = temp_outside_data[\"temperatureItem0\"].mean()\n",
    "                else:\n",
    "                    outside_temp_val = np.nan\n",
    "\n",
    "                # Get M2 temperature\n",
    "                m2_temp_data = await self.efd_client.select_time_series(\n",
    "                    \"lsst.sal.MTM2.temperature\",\n",
    "                    [\"ring6\"],\n",
    "                    Time(rec_start, scale=\"utc\"),\n",
    "                    Time(rec_end, scale=\"utc\") + self.temp_time_window,\n",
    "                )\n",
    "                if \"ring6\" in m2_temp_data:\n",
    "                    m2_temp_val = m2_temp_data[\"ring6\"].mean()\n",
    "                else:\n",
    "                    m2_temp_val = np.nan\n",
    "\n",
    "                # Get cam temperature\n",
    "                cam_temp_data = await self.efd_client.select_time_series(\n",
    "                    \"lsst.sal.ESS.temperature\",\n",
    "                    [\"temperatureItem0\"],\n",
    "                    Time(rec_start, scale=\"utc\"),\n",
    "                    Time(rec_end, scale=\"utc\") + self.temp_time_window,\n",
    "                    index=111,\n",
    "                )\n",
    "                if \"temperatureItem0\" in cam_temp_data:\n",
    "                    cam_air_temp_val = cam_temp_data[\"temperatureItem0\"].mean()\n",
    "                else:\n",
    "                    cam_air_temp_val = np.nan\n",
    "\n",
    "                # Get temperature above m1m3\n",
    "                temp_m1m3_data = await self.efd_client.select_time_series(\n",
    "                    \"lsst.sal.ESS.temperature\",\n",
    "                    [\"temperatureItem0\"],\n",
    "                    Time(rec_start, scale=\"utc\"),\n",
    "                    Time(rec_end, scale=\"utc\") + self.temp_time_window,\n",
    "                    index=113,\n",
    "                    convert_influx_index=True\n",
    "                )\n",
    "                if \"temperatureItem0\" in temp_m1m3_data:\n",
    "                    above_m1m3_temp_val = temp_m1m3_data[\"temperatureItem0\"].mean()\n",
    "                else:\n",
    "                    above_m1m3_temp_val = np.nan\n",
    "\n",
    "                # Get inside dome air temperature\n",
    "                inside_air_data = await self.efd_client.select_time_series(\n",
    "                    \"lsst.sal.ESS.temperature\",\n",
    "                    [\"temperatureItem0\"],\n",
    "                    Time(rec_start, scale=\"utc\"),\n",
    "                    Time(rec_end, scale=\"utc\") + self.temp_time_window,\n",
    "                    index=112,\n",
    "                    convert_influx_index=True\n",
    "                )\n",
    "                if \"temperatureItem0\" in inside_air_data:\n",
    "                    inside_air_temp_val = inside_air_data[\"temperatureItem0\"].mean()\n",
    "                else:\n",
    "                    inside_air_temp_val = np.nan\n",
    "\n",
    "                lut.append(lut_val)\n",
    "                above_m1m3_temp.append(above_m1m3_temp_val)\n",
    "                inside_air_temp.append(inside_air_temp_val)\n",
    "                cam_air_temp.append(cam_air_temp_val)\n",
    "                m2_temp.append(m2_temp_val)\n",
    "                outside_temp.append(outside_temp_val)\n",
    "                states.append(states_val)\n",
    "                days.append(day_obs)\n",
    "                seqs.append(seq)\n",
    "                correction_seq.append(seq_num_corr)\n",
    "\n",
    "            # Calculate FWHM Zernike contributions\n",
    "            efd_table = pd.DataFrame(\n",
    "                {\n",
    "                    \"day_obs\": days,\n",
    "                    \"seq\": seqs,\n",
    "                    \"inside_dome_air_temp\": inside_air_temp,\n",
    "                    \"cam_air_temp\": cam_air_temp,\n",
    "                    \"m2_temp\": m2_temp,\n",
    "                    \"above_m1m3_temp\": above_m1m3_temp,\n",
    "                    \"outside_temp\": outside_temp,\n",
    "                    \"lut_state\": lut,\n",
    "                    \"dof_state\": states,\n",
    "                    \"seq_num_corr\": correction_seq,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            self.table = pd.merge(\n",
    "                self.table, efd_table, how=\"left\", on=[\"seq\", \"day_obs\"]\n",
    "            )\n",
    "            m1m3_gradient_table = await get_m1m3_gradients(self.efd_client, unique_day_seq)\n",
    "            self.table = pd.merge(\n",
    "                self.table, m1m3_gradient_table, how=\"left\", on=[\"seq\", \"day_obs\"]\n",
    "            )\n",
    "            self.table[\"m2_delta_t\"] = (\n",
    "                self.table[\"m2_temp\"] - self.table[\"inside_dome_air_temp\"]\n",
    "            )\n",
    "            self.table[\"dome_delta_t\"] = (\n",
    "                self.table[\"outside_temp\"] - self.table[\"inside_dome_air_temp\"]\n",
    "            )\n",
    "            self.table[\"cam_m1m3_delta_t\"] = (\n",
    "                self.table[\"cam_air_temp\"] - self.table[\"above_m1m3_temp\"]\n",
    "            )\n",
    "\n",
    "        return self.table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2e081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T23:35:10.794934Z",
     "iopub.status.busy": "2025-11-21T23:35:10.793570Z",
     "iopub.status.idle": "2025-11-21T23:35:10.803586Z",
     "shell.execute_reply": "2025-11-21T23:35:10.802752Z",
     "shell.execute_reply.started": "2025-11-21T23:35:10.794888Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "zk_groups = [[0], [11 - 4], [1, 2], [3,4], [5, 6], [22]]\n",
    "zk_group_labels = ['Z4', 'Z11', 'Z5 / Z6', 'Z7 / Z8', ' Z9 / Z10', 'Z22']\n",
    "\n",
    "groups = [[0], [5], [1, 2, 6, 7], [3, 4], [8,9]]\n",
    "group_labels = [' M2 dz', 'Cam dz', 'Decenters', 'M2 tilts', 'Cam tilts']\n",
    "labels = ['m2 dz', 'm2 dx', 'm2 dy', 'm2 rx', 'm2 ry',\n",
    "          'cam dz', 'cam dx', 'cam dy', 'cam rx', 'cam ry']\n",
    "\n",
    "\n",
    "mirror_groups = [[10, 11, 30, 31], [12, 34], [13, 14, 32, 33], [15, 16, 35, 36], [17, 18, 37, 38]]\n",
    "mirror_group_labels = ['Astig', 'Spherical', 'Trefoil', 'Coma', 'Quad']\n",
    "all_labels = ['M2 dz', 'M2 dx', 'M2 dy', 'M2 rx', 'M2 ry',\n",
    "     'cam dz', 'cam dx', 'cam dy', 'cam rx', 'cam ry',\n",
    "     '$B_{{1,1}}$', '$B_{{1,2}}$', '$B_{{1,3}}$', '$B_{{1,4}}$', '$B_{{1,5}}$',\n",
    "     '$B_{{1,6}}$', '$B_{{1,7}}$', '$B_{{1,8}}$', '$B_{{1,9}}$', '$B_{{1,10}}$',\n",
    "     '$B_{{1,11}}$', '$B_{{1,12}}$', '$B_{{1,13}}$', '$B_{{1,14}}$', '$B_{{1,15}}$',\n",
    "     '$B_{{1,16}}$', '$B_{{1,17}}$', '$B_{{1,18}}$', '$B_{{1,19}}$', '$B_{{1,20}}$',\n",
    "     '$B_{{2,1}}$', '$B_{{2,2}}$', '$B_{{2,3}}$', '$B_{{2,4}}$', '$B_{{2,5}}$',\n",
    "     '$B_{{2,6}}$', '$B_{{2,7}}$', '$B_{{2,8}}$', '$B_{{2,9}}$', '$B_{{2,10}}$',\n",
    "     '$B_{{2,11}}$', '$B_{{2,12}}$', '$B_{{2,13}}$', '$B_{{2,14}}$', '$B_{{2,15}}$',\n",
    "     '$B_{{2,16}}$', '$B_{{2,17}}$', '$B_{{2,18}}$', '$B_{{2,19}}$', '$B_{{2,20}}$'\n",
    "     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ea4ac",
   "metadata": {},
   "source": [
    "## Simplified Nightly Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756469de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T15:07:00.304601Z",
     "iopub.status.busy": "2025-11-24T15:07:00.304266Z",
     "iopub.status.idle": "2025-11-24T15:07:06.835497Z",
     "shell.execute_reply": "2025-11-24T15:07:06.834252Z",
     "shell.execute_reply.started": "2025-11-24T15:07:00.304573Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"no_proxy\"] += \",.consdb\"\n",
    "db = AOSDatabase(day_obs=day_obs, seq_min=seq_min, seq_max=seq_max)\n",
    "await db.create(simplified=True)\n",
    "table = db.table\n",
    "print(table['rotation_angle'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc4a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T15:07:08.113580Z",
     "iopub.status.busy": "2025-11-24T15:07:08.113248Z",
     "iopub.status.idle": "2025-11-24T15:07:08.136593Z",
     "shell.execute_reply": "2025-11-24T15:07:08.135602Z",
     "shell.execute_reply.started": "2025-11-24T15:07:08.113553Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(table)>0:\n",
    "    filtered_table = table[table['day_obs'] == day_obs]\n",
    "    #filtered_table['rotation_angle'] = filtered_table['rotation_angle'].astype(float) # Had to add this line ??\n",
    "    raw_filtered_table = table[table['day_obs'] == day_obs]\n",
    "    filtered_table = filtered_table.select_dtypes(include=\"number\")\n",
    "    filtered_table['band'] = raw_filtered_table['band']\n",
    "    filtered_table = filtered_table.groupby(\"seq\").agg({col: 'first' if col == 'band' else 'mean' for col in filtered_table.columns})\n",
    "    \n",
    "    # -- AOS jumps\n",
    "    aos_diff = filtered_table[\"aos_fwhm\"].diff()\n",
    "    jump_indices = filtered_table[\"seq\"][aos_diff > 0.3].tolist()\n",
    "    \n",
    "    # -- States array and labels\n",
    "    states_per_seq = (\n",
    "        raw_filtered_table[[\"seq\", \"zernikes_fwhm\"]]\n",
    "        .drop_duplicates(\"seq\")\n",
    "        .dropna(subset=[\"zernikes_fwhm\"])\n",
    "        .set_index(\"seq\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    zernikes_fwhm = np.vstack(states_per_seq[\"zernikes_fwhm\"].values)\n",
    "    seqs = states_per_seq.index.values\n",
    "else:\n",
    "    print(f'No  data available for {day_obs},  seq_nums {seq_min}-{seq_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a9fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T15:07:09.556772Z",
     "iopub.status.busy": "2025-11-24T15:07:09.556420Z",
     "iopub.status.idle": "2025-11-24T15:07:11.362699Z",
     "shell.execute_reply": "2025-11-24T15:07:11.361576Z",
     "shell.execute_reply.started": "2025-11-24T15:07:09.556745Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(table)>0:\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "\n",
    "    linewidth = 0.7\n",
    "    # Top 5x4 GridSpec occupies the upper half\n",
    "    gs_top = gridspec.GridSpec(\n",
    "        nrows=5, ncols=4,\n",
    "        width_ratios=[4, 2, 2, 2],\n",
    "        height_ratios=[1]*5,\n",
    "        hspace=0.0,\n",
    "        wspace=0.25,\n",
    "        top=0.97,\n",
    "        bottom=0.54  # ends halfway down\n",
    "    )\n",
    "    \n",
    "    # Bottom 5x4 GridSpec occupies the lower half\n",
    "    gs_bot = gridspec.GridSpec(\n",
    "        nrows=5, ncols=4,\n",
    "        width_ratios=[4, 2, 2, 2],\n",
    "        height_ratios=[1]*5,\n",
    "        hspace=0.0,\n",
    "        top=0.46,\n",
    "        bottom=0.05\n",
    "    )\n",
    "    \n",
    "    # -- Left column: Survey performance\n",
    "    axes = []\n",
    "    for i in range(5):\n",
    "        ax = fig.add_subplot(gs_top[i, 0], sharex=axes[0] if i > 0 else None)\n",
    "        axes.append(ax)\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table['fwhm_zenith_500nm'], s=3, label='FWHM_Zenith_500nm')\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table['donut_blur_fwhm'], s=3, label='Donut Blur FWHM')\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table[\"psf_fwhm_95_05\"], s=3, label=\"FWHM:sqrt(95^2-5^2)\")\n",
    "    try:\n",
    "        axes[0].scatter(filtered_table['seq'], filtered_table['dimm'], s=3, label='DIMM')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    axes[0].legend(fontsize=8, bbox_to_anchor=(1.0, 1.5), loc='upper right')\n",
    "    ymin0 = 0; ymax0 = 2.0\n",
    "    axes[0].set_ylim(ymin0, ymax0)\n",
    "    axes[0].text(0, ymax0 * 1.1, \"... Faults\", fontsize=14, color='magenta')\n",
    "    axes[0].set_ylabel('FWHM [arcsec]')\n",
    "    axes[0].set_title(f'Delivered Seeing and System Variables')\n",
    "    axes[1].scatter(filtered_table['seq'], filtered_table[\"aos_fwhm\"], s=3)\n",
    "    axes[2].scatter(filtered_table['seq'], filtered_table['elevation'], color='k', s=3)\n",
    "    axes[3].scatter(filtered_table['seq'], filtered_table['azimuth'], color='k', s=3)\n",
    "    axes[4].scatter(filtered_table['seq'], filtered_table['rotation_angle'], color='k', s=3)\n",
    "    \n",
    "    axes[0].set_ylabel('FWHM\\n[arcsec]')\n",
    "    axes[1].set_ylabel('AOS FWHM\\n[arcsec]')\n",
    "    axes[2].set_ylabel('Elevation\\n[deg]')\n",
    "    axes[3].set_ylabel('Azimuth\\n[deg]')\n",
    "    axes[4].set_ylabel('Rotation\\n[deg]')\n",
    "    axes[4].set_xlabel('Sequence Number')\n",
    "    \n",
    "    annotate_bands(filtered_table, axes[4])\n",
    "    axes[4].legend(ncols=3)\n",
    "    \n",
    "    \n",
    "    for ax in axes[1::]:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    # Add block boundaries and names\n",
    "    blocks = find_blocks(table) # Find active blocks\n",
    "    maxSeq = max(table['seq'].values)\n",
    "    for i, changeSeq in enumerate(blocks['seq']):\n",
    "        if i < len(blocks) - 1:\n",
    "            changeWidth = blocks['seq'].iloc[i+1] - changeSeq\n",
    "        else:\n",
    "            changeWidth = maxSeq - changeSeq\n",
    "        for ax in axes[0::]:\n",
    "            ax.axvline(changeSeq, ls = '--', color='k', linewidth=linewidth, alpha=0.5)\n",
    "        if changeWidth > 5:\n",
    "            (ymin, ymax) = axes[1].get_ylim()\n",
    "            ytext = ymin = (ymax - ymin) * 0.5\n",
    "            axes[1].text(int(changeSeq + changeWidth / 2 - 2), ytext, \n",
    "                         blocks['block_after'].iloc[i], fontsize=8, rotation=90, alpha=0.6) \n",
    "    # Now plot the faults\n",
    "    faults = table[table['faults'].notnull()] \n",
    "    for k in range(len(faults)):\n",
    "        for ax in axes[0::]:\n",
    "            ax.axvline(faults['seq'].iloc[k], color='magenta', ls=':')\n",
    "        \n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    for ax in axes:\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction='in', which='both')\n",
    "    \n",
    "    \n",
    "    # -- Right column: DoF plots with shared x-axis (not y)\n",
    "    axes = [fig.add_subplot(gs_top[i, 1]) for i in range(5)]\n",
    "    for id_group, (ax, zk_group) in enumerate(zip(axes, zk_groups)):\n",
    "        zk_labels = zk_group_labels[id_group]\n",
    "        for zk_idx, i in enumerate(zk_group):\n",
    "            if len(zk_group) == 1:\n",
    "                zk_label = zk_labels\n",
    "            if len(zk_group) == 2:\n",
    "                zk_label = zk_labels.split('/')[zk_idx].strip()\n",
    "            color = 'black' if zk_idx == 0 else 'gray' if zk_idx == 1 else None\n",
    "            vals = zernikes_fwhm[:, i]\n",
    "            ax.scatter(seqs, vals, s=5, color=color, label=zk_label)\n",
    "        ax.set_ylabel(zk_group_labels[id_group])\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction=\"in\")\n",
    "        ax.legend(bbox_to_anchor=(1.22, 0.5), loc='center right')\n",
    "    \n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "        ax.grid(True, alpha=0.5)\n",
    "    for ax in axes:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    axes[-1].set_xlabel(\"Sequence Number\")\n",
    "    axes[0].set_title(f'Optical Aberrations')\n",
    "    \n",
    "    fig.suptitle(\"Survey Mode Performance Simplified – Day \" + str(day_obs), fontsize=18, x=0.35, y=1.03)\n",
    "    \n",
    "else:\n",
    "    print('No data to plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44666314-bc9f-49ad-9a29-c1a95ba1e7fe",
   "metadata": {},
   "source": [
    "## Full Nightly Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde02a-da5c-45b6-9a53-4945cfc5d82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:24:37.319662Z",
     "iopub.status.busy": "2025-11-25T14:24:37.319328Z",
     "iopub.status.idle": "2025-11-25T14:28:29.492918Z",
     "shell.execute_reply": "2025-11-25T14:28:29.491623Z",
     "shell.execute_reply.started": "2025-11-25T14:24:37.319615Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "db = AOSDatabase(day_obs=day_obs, seq_min=seq_min, seq_max=seq_max)\n",
    "await db.create(simplified=False)\n",
    "table = db.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596b008-4095-4e84-85df-ea38f4d8d83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:30:53.079988Z",
     "iopub.status.busy": "2025-11-25T14:30:53.079651Z",
     "iopub.status.idle": "2025-11-25T14:30:53.110739Z",
     "shell.execute_reply": "2025-11-25T14:30:53.109474Z",
     "shell.execute_reply.started": "2025-11-25T14:30:53.079961Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(table)>0:\n",
    "    filtered_table = table[table['day_obs'] == day_obs]\n",
    "    #filtered_table['rotation_angle'] = filtered_table['rotation_angle'].astype(float) # Had to add this line ??\n",
    "    raw_filtered_table = table[table['day_obs'] == day_obs]\n",
    "    filtered_table = filtered_table.select_dtypes(include=\"number\")\n",
    "    filtered_table['band'] = raw_filtered_table['band']\n",
    "    filtered_table = filtered_table.groupby(\"seq\").agg({col: 'first' if col == 'band' else 'mean' for col in filtered_table.columns})\n",
    "    \n",
    "    # -- AOS jumps\n",
    "    aos_diff = filtered_table[\"aos_fwhm\"].diff()\n",
    "    jump_indices = filtered_table[\"seq\"][aos_diff > 0.3].tolist()\n",
    "    \n",
    "    # -- States array and labels\n",
    "    states_per_seq = (\n",
    "        raw_filtered_table[[\"seq\", \"dof_state\", \"zernikes_fwhm\", \"lut_state\"]]\n",
    "        .drop_duplicates(\"seq\")\n",
    "        .dropna(subset=[\"dof_state\", \"zernikes_fwhm\", \"lut_state\"])\n",
    "        .set_index(\"seq\")\n",
    "    )\n",
    "    \n",
    "    dof_state = np.vstack(states_per_seq[\"dof_state\"].values)\n",
    "    zernikes_fwhm = np.vstack(states_per_seq[\"zernikes_fwhm\"].values)\n",
    "    lut_state = np.vstack(states_per_seq[\"lut_state\"].values)\n",
    "    seqs = states_per_seq.index.values\n",
    "else:\n",
    "    print(f'No  data available for {day_obs},  seq_nums {seq_min}-{seq_max}')\n",
    "len(filtered_table['rotation_angle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ec612-0491-426e-8c39-dc28ec8e8982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:30:54.187228Z",
     "iopub.status.busy": "2025-11-25T14:30:54.185820Z",
     "iopub.status.idle": "2025-11-25T14:31:01.581016Z",
     "shell.execute_reply": "2025-11-25T14:31:01.579950Z",
     "shell.execute_reply.started": "2025-11-25T14:30:54.187130Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(table)>0:\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    \n",
    "    linewidth = 0.7\n",
    "    # Top 5x4 GridSpec occupies the upper half\n",
    "    gs_top = gridspec.GridSpec(\n",
    "        nrows=6, ncols=4,\n",
    "        width_ratios=[4, 2, 2, 2],\n",
    "        height_ratios=[1]*6,\n",
    "        hspace=0.0,\n",
    "        wspace=0.25,\n",
    "        top=0.97,\n",
    "        bottom=0.54  # ends halfway down\n",
    "    )\n",
    "    \n",
    "    # Bottom 5x4 GridSpec occupies the lower half\n",
    "    gs_bot = gridspec.GridSpec(\n",
    "        nrows=5, ncols=4,\n",
    "        width_ratios=[4, 2, 2, 2],\n",
    "        height_ratios=[1]*5,\n",
    "        hspace=0.0,\n",
    "        wspace=0.25,\n",
    "        top=0.46,\n",
    "        bottom=0.05\n",
    "    )\n",
    "    \n",
    "    # -- Left column: Survey performance\n",
    "    axes = []\n",
    "    for i in range(6):\n",
    "        ax = fig.add_subplot(gs_top[i, 0], sharex=axes[0] if i > 0 else None)\n",
    "        axes.append(ax)\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table['fwhm_zenith_500nm'], s=3, label='FWHM_Zenith_500nm')\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table['donut_blur_fwhm'], s=3, label='Donut Blur FWHM')\n",
    "    axes[0].scatter(filtered_table['seq'], filtered_table[\"psf_fwhm_95_05\"], s=3, label=\"FWHM:sqrt(95^2-5^2)\")\n",
    "    try:\n",
    "        axes[0].scatter(filtered_table['seq'], filtered_table['dimm'], s=3, label='DIMM')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    axes[0].legend(fontsize=8, bbox_to_anchor=(1.0, 1.6), loc='upper right')\n",
    "    ymin0 = 0; ymax0 = 2.0\n",
    "    axes[0].set_ylim(ymin0, ymax0)\n",
    "    axes[0].text(0, ymax0 * 1.1, \"... Faults\", fontsize=14, color='magenta')\n",
    "    axes[0].set_ylabel('FWHM [arcsec]')\n",
    "    axes[0].set_title(f'Delivered Seeing and System Variables')\n",
    "    axes[1].scatter(filtered_table['seq'], filtered_table[\"aos_fwhm\"], s=3, label='AOS FWHM')\n",
    "    axes[2].scatter(filtered_table['seq'], filtered_table['elevation'], color='k', s=3)\n",
    "    axes[3].scatter(filtered_table['seq'], filtered_table['azimuth'], color='k', s=3)\n",
    "    axes[4].scatter(filtered_table['seq'], filtered_table['rotation_angle'], color='k', s=3)\n",
    "    max_corr_lag = 10\n",
    "    corr_lag = filtered_table['seq'] - filtered_table['seq_num_corr']\n",
    "    corr_lag = np.clip(corr_lag, 0, max_corr_lag)\n",
    "    axes[5].scatter(filtered_table['seq'], corr_lag, color='k', s=3)\n",
    "    \n",
    "    axes[0].set_ylabel('FWHM\\n[arcsec]')\n",
    "    axes[1].set_ylabel('AOS FWHM\\n[arcsec]')\n",
    "    axes[2].set_ylabel('Elevation\\n[deg]')\n",
    "    axes[3].set_ylabel('Azimuth\\n[deg]')\n",
    "    axes[4].set_ylabel('Rotator\\n[deg]')\n",
    "    axes[5].set_ylabel('Correction Lag\\n[# of visits]')\n",
    "    axes[5].set_xlabel('Sequence Number')\n",
    "    \n",
    "    annotate_bands(filtered_table, axes[5])\n",
    "    axes[5].legend(ncols=3, fontsize=8)\n",
    "    \n",
    "    \n",
    "    for ax in axes[1::]:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    # Add block boundaries and names\n",
    "    blocks = find_blocks(table) # Find active blocks\n",
    "    maxSeq = max(table['seq'].values)\n",
    "    for i, changeSeq in enumerate(blocks['seq']):\n",
    "        if i < len(blocks) - 1:\n",
    "            changeWidth = blocks['seq'].iloc[i+1] - changeSeq\n",
    "        else:\n",
    "            changeWidth = maxSeq - changeSeq\n",
    "        for ax in axes[0::]:\n",
    "            ax.axvline(changeSeq, ls = '--', color='k', linewidth=linewidth, alpha=0.5)\n",
    "        if changeWidth > 5:\n",
    "            (ymin1, ymax1) = axes[1].get_ylim()\n",
    "            ytext = ymin1 = (ymax1 - ymin1) * 0.5\n",
    "            axes[1].text(int(changeSeq + changeWidth / 2 - 2), ytext, \n",
    "                         blocks['block_after'].iloc[i], fontsize=8, rotation=90, alpha=0.6)    \n",
    "\n",
    "    # Now plot the faults\n",
    "    faults = table[table['faults'].notnull()] \n",
    "    for k in range(len(faults)):\n",
    "        for ax in axes[0::]:\n",
    "            ax.axvline(faults['seq'].iloc[k], color='magenta', ls=':')\n",
    "\n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    for ax in axes:\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction='in', which='both')\n",
    "    \n",
    "    # Thermal gradients \n",
    "    axes[0] = fig.add_subplot(gs_bot[0:2, 0])\n",
    "    for i in range(2,5):\n",
    "        axes[i] = fig.add_subplot(gs_bot[i, 0])\n",
    "    plot_m1m3_gradients(filtered_table, axes[0])\n",
    "    axes[2].scatter(filtered_table['seq'], filtered_table['m2_delta_t'], color='k', s=3)\n",
    "    axes[3].scatter(filtered_table['seq'], filtered_table['cam_m1m3_delta_t'], color='k', s=3)\n",
    "    axes[4].scatter(filtered_table['seq'], filtered_table['dome_delta_t'], color='k', s=3)\n",
    "    \n",
    "    axes[0].set_ylabel(f'M1M3 Gradients\\n[C]')\n",
    "    axes[2].set_ylabel('M2 - Dome\\n[C]')\n",
    "    axes[3].set_ylabel('Cam - M1M3\\n[C]')\n",
    "    axes[4].set_ylabel('Out - Dome\\n[C]')\n",
    "    axes[4].set_xlabel('Sequence Number')\n",
    "    \n",
    "    for ax in axes:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    for ax in axes:\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction='in', which='both')\n",
    "    axes[0].set_title(f'Thermal Gradients')\n",
    "    \n",
    "    # -- Right column: DoF plots with shared x-axis (not y)\n",
    "    axes = [fig.add_subplot(gs_top[i, 1]) for i in range(6)]\n",
    "    for id_group, (ax, zk_group) in enumerate(zip(axes, zk_groups)):\n",
    "        zk_labels = zk_group_labels[id_group]\n",
    "        for zk_idx, i in enumerate(zk_group):\n",
    "            if len(zk_group) == 1:\n",
    "                zk_label = zk_labels\n",
    "            if len(zk_group) == 2:\n",
    "                zk_label = zk_labels.split('/')[zk_idx].strip()\n",
    "            color = 'black' if zk_idx == 0 else 'gray' if zk_idx == 1 else None\n",
    "            vals = zernikes_fwhm[:, i]\n",
    "            ax.scatter(seqs, vals, s=5, color=color, label=zk_label)\n",
    "        ax.set_ylabel(zk_group_labels[id_group])\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction=\"in\")\n",
    "        ax.legend(bbox_to_anchor=(1.22, 0.5), loc='center right', frameon=False)\n",
    "    \n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "        ax.grid(True, alpha=0.5)\n",
    "    for ax in axes:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    axes[-1].set_xlabel(\"Sequence Number\")\n",
    "    axes[0].set_title(f'Optical Aberrations')\n",
    "    \n",
    "    \n",
    "    # -- Right column: DoF plots with shared x-axis (not y)\n",
    "    axes = [fig.add_subplot(gs_bot[i, 1]) for i in range(5)]\n",
    "    for id_group, (ax, dof_group) in enumerate(zip(axes, groups)):\n",
    "        for i in dof_group:\n",
    "            vals = (lut_state[:, i] + dof_state[:, i])\n",
    "            ax.scatter(seqs, vals, label=f\"{labels[i]}\", s=3)\n",
    "        ax.set_ylabel(group_labels[id_group])\n",
    "        ax.grid(True, alpha=0.5)\n",
    "        ax.tick_params(direction=\"in\")\n",
    "        ax.legend(bbox_to_anchor=(1.28, 0.5), loc='center right', frameon=False)\n",
    "    \n",
    "    for ax in axes[:-1]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "        ax.grid(True, alpha=0.5)\n",
    "    for ax in axes:\n",
    "        for x in jump_indices:\n",
    "            ax.axvline(x=x, color='red', linestyle='--', linewidth=linewidth)\n",
    "    axes[0].set_title(f'Hexapods State (LUT + trim)')\n",
    "    axes[-1].set_xlabel(\"Sequence Number\")\n",
    "    \n",
    "    my_suptitle = fig.suptitle(\"Survey Mode Performance and AOS DoFs – Day \" + str(day_obs), fontsize=18, x=0.35, y=1.03)\n",
    "else:\n",
    "    print('No data to plot')\n",
    "fig.savefig(f\"/home/cslage/MTAOS/times_square_notebooks/Full_Night_Report_{day_obs}.png\", bbox_inches='tight', pad_inches=1.2, bbox_extra_artists=[my_suptitle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0377b-1301-4a53-97ee-ba27f0a97ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8287-d4e3-4d45-be08-084b7debef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dof_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ae2a4-4ce4-4607-902f-c3ee3fe6ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dof_state[(dof_state['seq']>58) & (dof_state['seq']<=62)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02912de4-0772-4bd9-a216-c86b2ca18d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:31:50.251598Z",
     "iopub.status.busy": "2025-11-25T14:31:50.251267Z",
     "iopub.status.idle": "2025-11-25T14:31:50.259661Z",
     "shell.execute_reply": "2025-11-25T14:31:50.258330Z",
     "shell.execute_reply.started": "2025-11-25T14:31:50.251572Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_1 = 291\n",
    "seq_2 = 292\n",
    "\n",
    "for seq, dof in zip(seqs, dof_state):\n",
    "    if seq == seq_1:\n",
    "        dof_1 = dof\n",
    "    if seq == seq_2:\n",
    "        dof_2 = dof\n",
    "for j in range(50):\n",
    "    if j in [1,2,3,4,6,7,8,9]:\n",
    "        print(f\"seq {seq_1} {all_labels[j]} = {dof_1[j]:.4f} \\t \\t \\t seq {seq_2} {all_labels[j]} = {dof_2[j]:.4f}\")\n",
    "    else:\n",
    "        print(f\"seq {seq_1} {all_labels[j]} = {dof_1[j]:.4f} \\t \\t seq {seq_2} {all_labels[j]} = {dof_2[j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90246ab8-388a-4e87-b5e0-6f0e7f0b7b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T18:17:02.222492Z",
     "iopub.status.busy": "2025-11-23T18:17:02.222145Z",
     "iopub.status.idle": "2025-11-23T18:17:02.230002Z",
     "shell.execute_reply": "2025-11-23T18:17:02.228879Z",
     "shell.execute_reply.started": "2025-11-23T18:17:02.222465Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_1 =194\n",
    "seq_2 =195\n",
    "\n",
    "for seq, lut in zip(seqs, lut_state):\n",
    "    if seq == seq_1:\n",
    "        lut_1 = lut\n",
    "    if seq == seq_2:\n",
    "        lut_2 = lut\n",
    "for j in range(50):\n",
    "    if j in [3,4,8,9]:\n",
    "        print(f\"seq {seq_1} {all_labels[j]} = {lut_1[j]:.4f} \\t \\t \\t seq {seq_2} {all_labels[j]} = {lut_2[j]:.4f}\")\n",
    "    else:\n",
    "        print(f\"seq {seq_1} {all_labels[j]} = {lut_1[j]:.4f} \\t \\t seq {seq_2} {all_labels[j]} = {lut_2[j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e9ec4-2501-4a45-9202-f989d3b2f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498ca93-be4d-4d6e-a176-5363aa0e33ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282f370-5f9e-4bf0-9304-1760d39e2ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
